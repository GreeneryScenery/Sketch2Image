{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from PIL import Image, ImageDraw, ImageTk\n",
    "from tensorflow.keras.models import load_model\n",
    "from quickdraw_preprocess import *\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import io\n",
    "import torch\n",
    "import os\n",
    "import replicate\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_names = 30\n",
    "number_of_drawings = max_drawings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_names = random_names(number_of_names, seed = 2)\n",
    "random_names = ['basket',\n",
    " 'cruise ship',\n",
    " 'line',\n",
    " 'lighthouse',\n",
    " 'horse',\n",
    " 'calendar',\n",
    " 'lion',\n",
    " 'eyeglasses',\n",
    " 'eye',\n",
    " 'leg',\n",
    " 'streetlight',\n",
    " 'police car',\n",
    " 'tornado',\n",
    " 'sheep',\n",
    " 'beard',\n",
    " 'peanut',\n",
    " 'grass',\n",
    " 'lantern',\n",
    " 'circle',\n",
    " 'dresser',\n",
    " 'hat',\n",
    " 'bathtub',\n",
    " 'cannon',\n",
    " 'megaphone',\n",
    " 'rifle',\n",
    " 'fence',\n",
    " 'fan',\n",
    " 'stereo',\n",
    " 'bat',\n",
    " 'canoe']\n",
    "random_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelBinarizer()\n",
    "encoder.fit_transform(random_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(yhat):\n",
    "    decoded_predictions = []\n",
    "    for i in range(len(yhat[0])):\n",
    "        array = np.zeros(len(yhat[0]))\n",
    "        array[i] = 1\n",
    "        label = encoder.inverse_transform(np.expand_dims(array, 0))[0]\n",
    "        decoded_predictions.append((label, yhat[0][i] * 100))\n",
    "\n",
    "    text = ''\n",
    "    for pred in decoded_predictions:\n",
    "        text += '{}: {:.2f}%'.format(pred[0], pred[1]) + '\\n'\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import huggingface_hub\n",
    "huggingface_hub.snapshot_download(repo_id = 'GreeneryScenery/Sketch2ImageModels', local_dir = '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add your API token here\n",
    "os.environ[\"REPLICATE_API_TOKEN\"] = \"\"\n",
    "\n",
    "model_stable_diffusion_img2img = replicate.models.get(\"stability-ai/stable-diffusion-img2img\")\n",
    "version_stable_diffusion_img2img = model_stable_diffusion_img2img.versions.get(\"15a3689ee13b0d2616e98820eca31d4c3abcd36672df6afce5cb6feb1d66087d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diffuser(prompt, image, negative_prompt = 'Sketch, Drawing, Ugly, Bad, Badly drawn, Badly drawn art, Badly drawn cartoon, Badly drawn comic, Badly drawn manga, Badly drawn sketch, Badly drawn drawing', prompt_strength = 0.8, num_outputs = 1, num_inference_steps = 25, guidance_scale = 7.5, scheduler = 'DPMSolverMultistep', seed = 1):\n",
    "    inputs = {\n",
    "        # Input prompt\n",
    "        'prompt': prompt,\n",
    "\n",
    "        # The prompt NOT to guide the image generation. Ignored when not using\n",
    "        # guidance\n",
    "        # 'negative_prompt': negative_prompt,\n",
    "\n",
    "        # Inital image to generate variations of.\n",
    "        'image': image,\n",
    "\n",
    "        # Prompt strength when providing the image. 1.0 corresponds to full\n",
    "        # destruction of information in init image\n",
    "        'prompt_strength': prompt_strength,\n",
    "\n",
    "        # Number of images to output. Higher number of outputs may OOM.\n",
    "        # Range: 1 to 8\n",
    "        'num_outputs': num_outputs,\n",
    "\n",
    "        # Number of denoising steps\n",
    "        # Range: 1 to 500\n",
    "        'num_inference_steps': num_inference_steps,\n",
    "\n",
    "        # Scale for classifier-free guidance\n",
    "        # Range: 1 to 20\n",
    "        'guidance_scale': guidance_scale,\n",
    "\n",
    "        # Choose a scheduler.\n",
    "        'scheduler': scheduler,\n",
    "\n",
    "        # Random seed. Leave blank to randomize the seed\n",
    "        'seed': seed,\n",
    "    }\n",
    "\n",
    "    # https://replicate.com/stability-ai/stable-diffusion-img2img/versions/15a3689ee13b0d2616e98820eca31d4c3abcd36672df6afce5cb6feb1d66087d#output-schema\n",
    "    output = version_stable_diffusion_img2img.predict(**inputs)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'outputs'\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "input_dir = 'inputs'\n",
    "\n",
    "if not os.path.exists(input_dir):\n",
    "    os.mkdir(input_dir)\n",
    "\n",
    "edge_dir = 'edges'\n",
    "\n",
    "if not os.path.exists(edge_dir):\n",
    "    os.mkdir(edge_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_output(response, name):\n",
    "    name = re.sub(r'[^a-zA-Z0-9_\\-.]', '', name)\n",
    "    name = name[:100]\n",
    "    filename = f'{output_dir}/{name}_output.png'\n",
    "    if os.path.exists(filename):\n",
    "        i = 1\n",
    "        while True:\n",
    "            new_filename = f'{output_dir}/{name}{i}_output.png'\n",
    "            if not os.path.exists(new_filename):\n",
    "                filename = new_filename\n",
    "                break\n",
    "            i += 1\n",
    "\n",
    "    with open(filename, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "def save_input(image, name):\n",
    "    name = re.sub(r'[^a-zA-Z0-9_\\-.]', '', name)\n",
    "    name = name[:100]\n",
    "    filename = f'{input_dir}/{name}_input.png'\n",
    "    if os.path.exists(filename):\n",
    "        i = 1\n",
    "        while True:\n",
    "            new_filename = f'{input_dir}/{name}{i}_input.png'\n",
    "            if not os.path.exists(new_filename):\n",
    "                filename = new_filename\n",
    "                break\n",
    "            i += 1\n",
    "\n",
    "    image.save(filename)\n",
    "    return filename\n",
    "\n",
    "def save_edge(image, name):\n",
    "    name = re.sub(r'[^a-zA-Z0-9_\\-.]', '', name)\n",
    "    name = name[:100]\n",
    "    filename = f'{edge_dir}/{name}_edge.png'\n",
    "    if os.path.exists(filename):\n",
    "        i = 1\n",
    "        while True:\n",
    "            new_filename = f'{edge_dir}/{name}{i}_edge.png'\n",
    "            if not os.path.exists(new_filename):\n",
    "                filename = new_filename\n",
    "                break\n",
    "            i += 1\n",
    "\n",
    "    image.save(filename)\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from diffusers import AutoencoderKL, PNDMScheduler, UNet2DConditionModel, LMSDiscreteScheduler, DDIMScheduler, DDPMScheduler\n",
    "from transformers import CLIPTextModel, CLIPTokenizer\n",
    "from torch import nn\n",
    "from typing import List\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "class latent_guidance_predictor(nn.Module):\n",
    "    def __init__(self, output_dim, input_dim, num_encodings):\n",
    "        super(latent_guidance_predictor, self).__init__()\n",
    "        self.num_encodings = num_encodings\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(num_features=512),\n",
    "            nn.Linear(512, 256),         \n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(num_features=256),\n",
    "            nn.Linear(256, 128),     \n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(num_features=128),\n",
    "            nn.Linear(128, 64),      \n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(num_features=64),\n",
    "            nn.Linear(64, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # Concatenate input pixels with noise level t and positional encodings\n",
    "        pos_encoding = [torch.sin(2 * math.pi * t * (2 **-l)) for l in range(self.num_encodings)]\n",
    "        pos_encoding = torch.cat(pos_encoding, dim=-1)\n",
    "        x = torch.cat((x, t, pos_encoding), dim=-1)\n",
    "        x = x.flatten(start_dim=0, end_dim=2)\n",
    "        \n",
    "        return self.layers(x)\n",
    "\n",
    "@torch.no_grad()\n",
    "def to_latents(img:Image, vae, device = 'cpu'):\n",
    "    np_img = (np.array(img).astype(np.float32) / 255.0) * 2.0 - 1.0\n",
    "    np_img = np_img[None].transpose(0, 3, 1, 2)\n",
    "    torch_img = torch.from_numpy(np_img)\n",
    "    generator = torch.Generator(device).manual_seed(0)\n",
    "    latents = vae.encode(torch_img.to(vae.dtype).to(device)).latent_dist.sample(generator=generator)\n",
    "    latents = latents * 0.18215\n",
    "    return latents\n",
    "\n",
    "@torch.no_grad()\n",
    "def to_img(latents, vae, device = 'cpu'):\n",
    "    torch_img = vae.decode(latents.to(vae.dtype).to(device)).sample\n",
    "    torch_img = (torch_img / 2 + 0.5).clamp(0, 1)\n",
    "    np_img = torch_img.cpu().permute(0, 2, 3, 1).detach().numpy()[0]\n",
    "    np_img = (np_img * 255.0).astype(np.uint8)\n",
    "    img = Image.fromarray(np_img)\n",
    "    return img\n",
    "\n",
    "def noisy_latent(image, noise_scheduler, timesteps, device = 'cpu'):\n",
    "    noise = torch.randn(image.shape).to(device)\n",
    "    noisy_image = noise_scheduler.add_noise(image, noise, timesteps)\n",
    "    sqrt_alpha_prod = noise_scheduler.alphas_cumprod[timesteps].to(device) ** 0.5\n",
    "    sqrt_alpha_prod = sqrt_alpha_prod.flatten()\n",
    "    while len(sqrt_alpha_prod.shape) < len(image.shape):\n",
    "        sqrt_alpha_prod = sqrt_alpha_prod.unsqueeze(-1)\n",
    "    noise_level = noisy_image - (sqrt_alpha_prod * image)\n",
    "    return noisy_image, noise_level\n",
    "\n",
    "def save_tensors(module: nn.Module, features, name: str):\n",
    "    \"\"\" Process and save activations in the module. \"\"\"\n",
    "    if type(features) in [list, tuple]:\n",
    "        features = [f.detach().float() for f in features if f is not None and isinstance(f, torch.Tensor)]\n",
    "        setattr(module, name, features)\n",
    "    elif isinstance(features, dict):\n",
    "        features = {k: f.detach().float() for k, f in features.items()}\n",
    "        setattr(module, name, features)\n",
    "    else:\n",
    "        setattr(module, name, features.detach().float())\n",
    "\n",
    "def save_out_hook(self, inp, out):\n",
    "    save_tensors(self, out, 'activations')\n",
    "    return out\n",
    "\n",
    "def save_input_hook(self, inp, out):\n",
    "    save_tensors(self, inp[0], 'activations')\n",
    "    return out\n",
    "\n",
    "def extract_features(latent_image, blocks, unet, timesteps, text_embeddings):\n",
    "    latent_model_input = torch.cat([latent_image] * 2)\n",
    "    activations = []\n",
    "    save_hook = save_out_hook\n",
    "    feature_blocks = []\n",
    "    for idx, block in enumerate(unet.down_blocks):\n",
    "        if idx in blocks:\n",
    "            block.register_forward_hook(save_hook)\n",
    "            feature_blocks.append(block) \n",
    "            \n",
    "    for idx, block in enumerate(unet.up_blocks):\n",
    "        if idx in blocks:\n",
    "            block.register_forward_hook(save_hook)\n",
    "            feature_blocks.append(block)  \n",
    "    with torch.no_grad():\n",
    "        noise_pred = unet(latent_model_input, timesteps, encoder_hidden_states=text_embeddings).sample\n",
    "\n",
    "    # Extract activations\n",
    "    for block in feature_blocks:\n",
    "        activations.append(block.activations)\n",
    "        block.activations = None\n",
    "        \n",
    "    activations = [activations[0][0], activations[1][0], activations[2][0], activations[3][0], activations[4], activations[5], activations[6], activations[7]]\n",
    "    \n",
    "    return activations\n",
    "\n",
    "def resize_and_concatenate(activations: List[torch.Tensor], reference):\n",
    "    assert all([isinstance(acts, torch.Tensor) for acts in activations])\n",
    "    size = reference.shape[2:]\n",
    "    resized_activations = []\n",
    "    for acts in activations:\n",
    "        acts = nn.functional.interpolate(\n",
    "            acts, size=size, mode=\"bilinear\"\n",
    "        )\n",
    "        acts = acts[:1]\n",
    "        acts = acts.transpose(1,3)\n",
    "        resized_activations.append(acts)\n",
    "    \n",
    "    return torch.cat(resized_activations, dim=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_map(caption, vae, device, unet, lgp_path, strength, img_path):\n",
    "    # parser = argparse.ArgumentParser(description= \"Encode images\")\n",
    "    # parser.add_argument(\"--caption\", type=str, help=\"image caption\")\n",
    "    # parser.add_argument(\"--vae\", type=str, help=\"folder vae is located\", default=\"runwayml/stable-diffusion-v1-5\")\n",
    "    # parser.add_argument(\"--device\", type=str, help=\"Device to use\", default=\"cuda\", required=False)\n",
    "    # parser.add_argument(\"--unet\", type=str, help=\"folder unet subfolder is located\", default=\"runwayml/stable-diffusion-v1-5\")\n",
    "    # parser.add_argument(\"--LGP_path\", type=str, help=\"folder pre-trained LGP is located\")\n",
    "    # parser.add_argument(\"--noise_strength\", type=float, help=\"denoising strength\")\n",
    "    # parser.add_argument(\"--image_path\", type=str, help=\"folder skecth is located\")\n",
    "\n",
    "    # args = parser.parse_args()   \n",
    "    # device = args.device\n",
    "    # lgp_path = args.LGP_path\n",
    "    # img_path = args.image_path\n",
    "\n",
    "    blocks = [0,1,2,3]\n",
    "    # caption = args.caption\n",
    "    num_inference_steps = 50\n",
    "    batch_size = 1\n",
    "    guidance_scale = 8\n",
    "    # strength = args.noise_strength\n",
    "    eta = 0.0\n",
    "        \n",
    "    model = latent_guidance_predictor(output_dim=4, input_dim=7080, num_encodings=9).to(device)\n",
    "    checkpoint = torch.load(lgp_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "\n",
    "    vae = AutoencoderKL.from_pretrained(vae, subfolder= \"vae\", use_auth_token=False).to(device)\n",
    "    unet = UNet2DConditionModel.from_pretrained(unet, subfolder=\"unet\", use_auth_token=False).to(device)\n",
    "    tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "    text_encoder = CLIPTextModel.from_pretrained(\"openai/clip-vit-large-patch14\").to(device)\n",
    "    noise_scheduler = DDPMScheduler.from_pretrained(\"runwayml/stable-diffusion-v1-5\", subfolder=\"scheduler\")\n",
    "\n",
    "    offset = noise_scheduler.config.get(\"steps_offset\", 0)\n",
    "\n",
    "    noise_scheduler.set_timesteps(num_inference_steps)\n",
    "\n",
    "    # get the original timestep using init_timestep\n",
    "    init_timestep = int(num_inference_steps * strength) + offset\n",
    "    init_timestep = min(init_timestep, num_inference_steps)\n",
    "\n",
    "    if isinstance(noise_scheduler, LMSDiscreteScheduler):\n",
    "        timesteps = torch.tensor([num_inference_steps - init_timestep] * batch_size, dtype=torch.long, device=device)\n",
    "    else:\n",
    "        timesteps = noise_scheduler.timesteps[-init_timestep]\n",
    "        timesteps = torch.tensor([timesteps] * batch_size, dtype=torch.long, device=device)\n",
    "        \n",
    "    text_input = tokenizer([caption], padding=\"max_length\", max_length=tokenizer.model_max_length, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        text_embeddings = text_encoder(text_input.input_ids.to(device))[0]\n",
    "    max_length = text_input.input_ids.shape[-1]\n",
    "    uncond_input = tokenizer(\n",
    "    [\"\"] * batch_size, padding=\"max_length\", max_length=max_length, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        uncond_embeddings = text_encoder(uncond_input.input_ids.to(device))[0]   \n",
    "    text_embeddings = torch.cat([uncond_embeddings, text_embeddings])\n",
    "\n",
    "    img = Image.open(img_path)\n",
    "    img = img.resize((512,512))\n",
    "    imagelatent = to_latents(img, vae)\n",
    "\n",
    "    noisy_image, noise_level = noisy_latent(imagelatent, noise_scheduler, timesteps)\n",
    "    noise_level = noise_level.transpose(1,3)\n",
    "\n",
    "    file_name = os.path.basename(img_path)\n",
    "    img_name = os.path.splitext(file_name)[0]\n",
    "\n",
    "    features = extract_features(noisy_image, blocks, unet, timesteps, text_embeddings)\n",
    "    features = resize_and_concatenate(features, imagelatent)\n",
    "\n",
    "    pred_edge_map = model(features, noise_level).unflatten(0, (1, 64, 64)).transpose(3, 1)\n",
    "    pred_edge_map = to_img(pred_edge_map, vae)\n",
    "    save_edge(pred_edge_map, img_name)\n",
    "    return pred_edge_map\n",
    "    #pred_edge_map.save(img_name + '-edge_map.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_controlnet_scribble = replicate.models.get(\"jagilley/controlnet-scribble\")\n",
    "version_controlnet_scribble = model_controlnet_scribble.versions.get(\"435061a1b5a4c1e26740464bf786efdfa9cb3a3ac488595a2de23e143fdb0117\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def controlnet(image, prompt, num_samples = '1', image_resolution = '512', ddim_steps = 20, scale = 9, seed = 1, eta = 0, a_prompt = 'best quality, extremely detailed', n_prompt = 'longbody, lowres, bad anatomy, bad hands, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality'):\n",
    "    # https://replicate.com/jagilley/controlnet-scribble/versions/435061a1b5a4c1e26740464bf786efdfa9cb3a3ac488595a2de23e143fdb0117#input\n",
    "    inputs = {\n",
    "        # Input image\n",
    "        'image': image,\n",
    "\n",
    "        # Prompt for the model\n",
    "        'prompt': prompt,\n",
    "\n",
    "        # Number of samples (higher values may OOM)\n",
    "        'num_samples': num_samples,\n",
    "\n",
    "        # Image resolution to be generated\n",
    "        'image_resolution': image_resolution,\n",
    "\n",
    "        # Steps\n",
    "        'ddim_steps': ddim_steps,\n",
    "\n",
    "        # Guidance Scale\n",
    "        # Range: 0.1 to 30\n",
    "        'scale': scale,\n",
    "\n",
    "        # Seed\n",
    "        'seed': seed,\n",
    "\n",
    "        # eta (DDIM)\n",
    "        'eta': eta,\n",
    "\n",
    "        # Added Prompt\n",
    "        'a_prompt': a_prompt,\n",
    "\n",
    "        # Negative Prompt\n",
    "        'n_prompt': n_prompt,\n",
    "    }\n",
    "\n",
    "    # https://replicate.com/jagilley/controlnet-scribble/versions/435061a1b5a4c1e26740464bf786efdfa9cb3a3ac488595a2de23e143fdb0117#output-schema\n",
    "    output = version_controlnet_scribble.predict(**inputs)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sheepscontrol = replicate.models.get('greeneryscenery/sheeps-control-v3')\n",
    "version_sheepscontrol = model_sheepscontrol.versions.get('2c9cdfc4e64142451ad71932a6e513bcc725012598e75d374867f71e2b53ff51')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sheepscontrol(image, prompt, seed = 0):\n",
    "    inputs ={\n",
    "        'seed': seed,\n",
    "        'text': prompt,\n",
    "        'image': image,\n",
    "    }\n",
    "\n",
    "    output = version_sheepscontrol.predict(**inputs)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_images(image):\n",
    "    img = image.copy()\n",
    "    _, binary_img = cv2.threshold(img, 254, 255, cv2.THRESH_BINARY_INV)\n",
    "    contours, hierarchy = cv2.findContours(binary_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rectangles = []\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        rectangles.append((x, y, w, h))\n",
    "    for rectangle in rectangles:\n",
    "        x, y, w, h = rectangle\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    #ipyplot.plot_images([img])\n",
    "\n",
    "    cropped_images = []\n",
    "    for rectangle in rectangles:\n",
    "        x, y, w, h = rectangle\n",
    "        cropped_img = image[y:y+h, x:x+w]\n",
    "        cropped_images.append(cropped_img)\n",
    "    \n",
    "    if len(cropped_images) == 0:\n",
    "        return None\n",
    "\n",
    "    min_size = 10\n",
    "\n",
    "    i = 0\n",
    "    while i < len(cropped_images):\n",
    "        x1, y1, w1, h1 = rectangles[i]\n",
    "        if w1 < min_size or h1 < min_size:\n",
    "            del cropped_images[i]\n",
    "            del rectangles[i]\n",
    "            continue\n",
    "        j = i + 1\n",
    "        while j < len(cropped_images):\n",
    "            x2, y2, w2, h2 = rectangles[j]\n",
    "            x_overlap = max(0, min(x1 + w1, x2 + w2) - max(x1, x2))\n",
    "            y_overlap = max(0, min(y1 + h1, y2 + h2) - max(y1, y2))\n",
    "            overlap_area = x_overlap * y_overlap\n",
    "            if overlap_area > 0:\n",
    "                area1 = w1 * h1\n",
    "                area2 = w2 * h2\n",
    "                if area1 >= area2:\n",
    "                    del cropped_images[j]\n",
    "                    del rectangles[j]\n",
    "                else:\n",
    "                    del cropped_images[i]\n",
    "                    del rectangles[i]\n",
    "                    i -= 1\n",
    "                    break\n",
    "            j += 1\n",
    "        i += 1\n",
    "    #ipyplot.plot_images(cropped_images)\n",
    "    return cropped_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer_magic_prompt = AutoTokenizer.from_pretrained(\"Gustavosta/MagicPrompt-Stable-Diffusion\")\n",
    "model_magic_prompt = AutoModelForCausalLM.from_pretrained(\"Gustavosta/MagicPrompt-Stable-Diffusion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_magic_prompt = \"[\\[\\]']+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def magic_prompt_generator(string):\n",
    "    input_magic_prompt = tokenizer_magic_prompt.encode(string, return_tensors='pt')\n",
    "    output_magic_prompt = model_magic_prompt.generate(input_magic_prompt, max_length=100, do_sample=True, top_k=50, top_p=0.95, temperature=0.5, num_return_sequences=1)\n",
    "    text_magic_prompt = tokenizer_magic_prompt.decode(output_magic_prompt[0], skip_special_tokens=True)\n",
    "    return text_magic_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_open_assistant = '<|prompter|>Please form a sentence describing an image using these words: |INPUT|. This sentence will be used for image generation in ControlNet and Stable Diffusion so be as descriptive and creative as possible, while not adding too much extra stuff.<|endoftext|><|assistant|>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"https://api-inference.huggingface.co/models/OpenAssistant/oasst-sft-1-pythia-12b\"\n",
    "headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\treturn response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_assistant_generator(string):\n",
    "    text_open_assistant = format_open_assistant.replace('|INPUT|', string)\n",
    "    # input_open_assistant = tokenizer_open_assistant.encode(text_open_assistant, return_tensors='pt')\n",
    "    # output_open_assistant = model_open_assistant.generate(input_open_assistant, max_length=100, do_sample=True, top_k=50, top_p=0.95, temperature=0.9, num_return_sequences=1)\n",
    "    # text_open_assistant = tokenizer_open_assistant.decode(output_open_assistant[0], skip_special_tokens=True)\n",
    "    output = query({\n",
    "        \"inputs\": text_open_assistant,\n",
    "    })\n",
    "    output = output[0]['generated_text']\n",
    "    return output.replace(text_open_assistant, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(string):\n",
    "    prompt = open_assistant_generator(string)\n",
    "    string = re.sub(rf'{regex_magic_prompt}', '', string)\n",
    "    string = f'{string},'\n",
    "    magic_prompt = magic_prompt_generator(string)\n",
    "    prompt = prompt + ' ' + magic_prompt\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpt_2_simple as gpt2\n",
    "\n",
    "sess = gpt2.start_tf_sess()\n",
    "gpt2.load_gpt2(sess)\n",
    "\n",
    "def gpt_2_generator(string):\n",
    "    prompt = gpt2.generate(sess, length=50, temperature=0.7, prefix=string, return_as_list=True)[0]\n",
    "    prompt = prompt.split('\\n')[0]\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cnn_model = load_model('models/cnn_model_4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter\n",
    "import customtkinter\n",
    "from tkinter import colorchooser, simpledialog, filedialog, ttk, Frame, PhotoImage\n",
    "import cv2\n",
    "import re\n",
    "\n",
    "customtkinter.set_appearance_mode(\"System\")  # Modes: \"System\" (standard), \"Dark\", \"Light\"\n",
    "customtkinter.set_default_color_theme(\"blue\")  # Themes: \"blue\" (standard), \"green\", \"dark-blue\"\n",
    "\n",
    "auto_text = True\n",
    "pen_color = 'black'\n",
    "pen_width = 5\n",
    "\n",
    "canvas_width = 800\n",
    "canvas_height = 800\n",
    "canvas = None\n",
    "img = Image.new('RGB', (canvas_width, canvas_height), color='white')\n",
    "draw = ImageDraw.Draw(img)\n",
    "\n",
    "def update_canvas():\n",
    "    canvas.image = ImageTk.PhotoImage(img)\n",
    "    canvas.create_image(0, 0, anchor='nw', image=canvas.image)\n",
    "\n",
    "class LineDrawer:\n",
    "    def __init__(self, image, canvas, app):\n",
    "        self.draw = ImageDraw.Draw(image)\n",
    "        self.prev_x = None\n",
    "        self.prev_y = None\n",
    "        self.strokes = []\n",
    "        self.buffer = []\n",
    "        self.canvas = canvas\n",
    "        self.image = image\n",
    "        self.app = app\n",
    "        self.current_stroke = dict()\n",
    "\n",
    "    def start_line(self, event):\n",
    "        self.current_stroke = dict()\n",
    "        self.buffer = []\n",
    "        self.prev_x = event.x\n",
    "        self.prev_y = event.y\n",
    "        self.current_stroke['color'] = pen_color\n",
    "        self.current_stroke['width'] = pen_width\n",
    "        self.current_stroke['points'] = [(self.prev_x, self.prev_y)]\n",
    "        update_canvas()\n",
    "\n",
    "    def continue_line(self, event):\n",
    "        if self.prev_x is not None and self.prev_y is not None:\n",
    "            x, y = event.x, event.y\n",
    "            self.draw.line([(self.prev_x, self.prev_y), (x, y)],\n",
    "                        width = pen_width, fill = pen_color)\n",
    "            self.prev_x, self.prev_y = x, y\n",
    "            self.current_stroke['points'].append((self.prev_x, self.prev_y))\n",
    "        update_canvas()\n",
    "\n",
    "    def end_line(self, event):\n",
    "        self.prev_x, self.prev_y = None, None\n",
    "        update_canvas()\n",
    "        self.app.classify_image(event)\n",
    "        self.strokes.append(self.current_stroke)\n",
    "    \n",
    "    def start_erase(self, event):\n",
    "        self.current_stroke = dict()\n",
    "        self.buffer = []\n",
    "        self.prev_x = event.x\n",
    "        self.prev_y = event.y\n",
    "        self.current_stroke['color'] = 'white'\n",
    "        self.current_stroke['width'] = pen_width\n",
    "        self.current_stroke['points'] = [(self.prev_x, self.prev_y)]\n",
    "        update_canvas()\n",
    "\n",
    "    def continue_erase(self, event):\n",
    "        if self.prev_x is not None and self.prev_y is not None:\n",
    "            x, y = event.x, event.y\n",
    "            self.draw.line([(self.prev_x, self.prev_y), (x, y)],\n",
    "                        width = pen_width, fill = 'white')\n",
    "            self.prev_x, self.prev_y = x, y\n",
    "            self.current_stroke['points'].append((self.prev_x, self.prev_y))\n",
    "        update_canvas()\n",
    "\n",
    "    def end_erase(self, event):\n",
    "        self.prev_x, self.prev_y = None, None\n",
    "        update_canvas()\n",
    "        self.app.classify_image(event)\n",
    "        self.strokes.append(self.current_stroke)\n",
    "\n",
    "    def get_strokes(self):\n",
    "        return self.strokes\n",
    "    \n",
    "    def undo(self, event):\n",
    "        if self.strokes != []:\n",
    "            self.draw.rectangle([(0, 0), (canvas_width, canvas_height)], fill='white')\n",
    "            for stroke in self.strokes[:-1]:\n",
    "                self.draw.line(stroke['points'], width = stroke['width'], fill = stroke['color'])\n",
    "            update_canvas()\n",
    "            self.buffer.append(self.strokes[-1])\n",
    "            self.strokes = self.strokes[:-1]\n",
    "            self.app.classify_image(event)\n",
    "    \n",
    "    def redo(self, event):\n",
    "        if self.buffer != []:\n",
    "            self.draw.rectangle([(0, 0), (canvas_width, canvas_height)], fill='white')\n",
    "            for stroke in self.strokes:\n",
    "                self.draw.line(stroke['points'], width = stroke['width'], fill = stroke['color'])\n",
    "            self.draw.line(self.buffer[-1]['points'], width = self.buffer[-1]['width'], fill = self.buffer[-1]['color'])\n",
    "            self.strokes.append(self.buffer[-1])\n",
    "            self.buffer = self.buffer[:-1]\n",
    "            update_canvas()\n",
    "            self.app.classify_image(event)\n",
    "    \n",
    "    def clear(self, event):\n",
    "        self.draw.rectangle([(0, 0), (canvas_width, canvas_height)], fill='white')\n",
    "        self.strokes = []\n",
    "        self.buffer = []\n",
    "        update_canvas()\n",
    "        self.app.classify_image(event)\n",
    "\n",
    "class App(customtkinter.CTk):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.crop = IntVar()\n",
    "        self.separate = IntVar()\n",
    "        self.magic = customtkinter.StringVar(value=\"on\")\n",
    "        self.open = customtkinter.StringVar(value=\"on\")\n",
    "\n",
    "        # configure window\n",
    "        self.title(\"Sketcher\")\n",
    "        self.geometry(f\"{1920}x{1080}\")\n",
    "        self.iconbitmap('assets/Sketcher.ico')\n",
    "\n",
    "        # configure grid layout (4x4)\n",
    "        self.grid_columnconfigure(1, weight=1)\n",
    "        self.grid_columnconfigure(2, weight=0)\n",
    "        self.grid_rowconfigure((0, 1), weight=1)\n",
    "\n",
    "        # create sidebar frame with widgets\n",
    "        self.sidebar_frame = customtkinter.CTkFrame(self, width=140, corner_radius=0)\n",
    "        self.sidebar_frame.grid(row=0, column=0, rowspan=4, sticky=\"nsew\")\n",
    "        self.sidebar_frame.grid_rowconfigure(4, weight=1)\n",
    "        self.logo_label = customtkinter.CTkLabel(self.sidebar_frame, text=\"Sketcher\", font=customtkinter.CTkFont(size=20, weight=\"bold\"))\n",
    "        self.logo_label.grid(row=0, column=0, padx=20, pady=(20, 10))\n",
    "        self.appearance_mode_label = customtkinter.CTkLabel(self.sidebar_frame, text=\"Appearance Mode:\", anchor=\"w\")\n",
    "        self.appearance_mode_label.grid(row=5, column=0, padx=20, pady=(10, 0))\n",
    "        self.appearance_mode_optionemenu = customtkinter.CTkOptionMenu(self.sidebar_frame, values=[\"Light\", \"Dark\", \"System\"],\n",
    "                                                                       command=self.change_appearance_mode_event)\n",
    "        self.appearance_mode_optionemenu.grid(row=6, column=0, padx=20, pady=(10, 10))\n",
    "        self.theme_label = customtkinter.CTkLabel(self.sidebar_frame, text=\"Theme:\", anchor=\"w\")\n",
    "        self.theme_label.grid(row=7, column=0, padx=20, pady=(10, 0))\n",
    "        self.theme_optionemenu = customtkinter.CTkOptionMenu(self.sidebar_frame, values=[\"blue\", \"dark-blue\", \"green\"],\n",
    "                                                                       command=self.change_theme_event)\n",
    "        self.theme_optionemenu.grid(row=8, column=0, padx=20, pady=(10, 10))\n",
    "        self.scaling_label = customtkinter.CTkLabel(self.sidebar_frame, text=\"UI Scaling:\", anchor=\"w\")\n",
    "        self.scaling_label.grid(row=9, column=0, padx=20, pady=(10, 0))\n",
    "        self.scaling_optionemenu = customtkinter.CTkOptionMenu(self.sidebar_frame, values=[\"80%\", \"90%\", \"100%\", \"110%\", \"120%\"],\n",
    "                                                               command=self.change_scaling_event)\n",
    "        self.scaling_optionemenu.grid(row=10, column=0, padx=20, pady=(10, 20))\n",
    "\n",
    "        # create main entry and button\n",
    "        self.prompt_entry = customtkinter.CTkEntry(self, placeholder_text=\"Prompt goes here...\")\n",
    "        self.prompt_entry.grid(row=2, column=1, columnspan=2, padx=(20, 20), pady=(0, 20), sticky=\"nsew\")\n",
    "        self.prompt_entry.bind(\"<KeyRelease>\", self.prompt_changed)\n",
    "\n",
    "        # create canvas\n",
    "        global canvas\n",
    "        canvas = Canvas(master=self, width=canvas_width, height=canvas_height, bg='white', cursor = \"@Posys_Cursor_Strokeless/Posy_pen.cur\")\n",
    "        canvas.grid(row=0, column=1, padx=(20, 0), pady=(40, 0), sticky='n')\n",
    "\n",
    "        self.bind('<Control-z>', self.undo)\n",
    "        self.bind('<Control-Z>', self.redo)\n",
    "\n",
    "        self.line_drawer = LineDrawer(img, canvas, self)\n",
    "        canvas.bind('<Button-1>', self.line_drawer.start_line)\n",
    "        canvas.bind('<B1-Motion>', self.line_drawer.continue_line)\n",
    "        canvas.bind('<ButtonRelease-1>', self.line_drawer.end_line)\n",
    "        canvas.bind(\"<Button-3>\", self.line_drawer.start_erase)\n",
    "        canvas.bind(\"<B3-Motion>\", self.line_drawer.continue_erase)\n",
    "        canvas.bind(\"<ButtonRelease-3>\", self.line_drawer.end_erase)\n",
    "\n",
    "        # create tabview\n",
    "        self.tabview = customtkinter.CTkTabview(self, width=400)\n",
    "        self.tabview.grid(row=0, column=2, padx=(20, 20), pady=(20, 10), sticky=\"nsew\")\n",
    "        self.tabview.add(\"Predictions\")\n",
    "        self.tabview.add(\"Generations\")\n",
    "        self.tabview.add(\"Settings\")\n",
    "        self.tabview.tab(\"Predictions\").grid_columnconfigure(0, weight=1)  # configure grid of individual tabs\n",
    "        self.tabview.tab(\"Generations\").grid_columnconfigure(0, weight=1)\n",
    "        self.tabview.tab(\"Settings\").grid_columnconfigure(0, weight=1)\n",
    "        \n",
    "        self.predictions_frame = customtkinter.CTkScrollableFrame(self.tabview.tab(\"Predictions\"), width=350, height=450)\n",
    "        self.predictions_frame.grid(row=0, column=0, padx=20, pady=20)\n",
    "        self.predictions_frame.grid_columnconfigure(0, weight=1)\n",
    "\n",
    "        self.best_label = customtkinter.CTkLabel(self.predictions_frame, text = 'Prediction:', font = ('Helvetica', 24, 'bold'), ) # cursor = '@Posys_Cursor_Strokeless/Posy_Strokeless.cur')\n",
    "        self.best_label.grid(row = 0, column = 0, padx = 5, pady = 5)\n",
    "        self.best_label.configure(wraplength = 300, text_color = 'green')\n",
    "\n",
    "        self.prediction_label = customtkinter.CTkLabel(self.predictions_frame, text = decode(np.expand_dims(np.zeros(number_of_names), 0)), ) # cursor = '@Posys_Cursor_Strokeless/Posy_Strokeless.cur')\n",
    "        self.prediction_label.grid(row=1, column=0, padx=5, pady=5)\n",
    "        self.prediction_label.configure(wraplength = 200, justify = RIGHT)\n",
    "\n",
    "        self.generation_frame = customtkinter.CTkScrollableFrame(self.tabview.tab(\"Generations\"), width=350, height=450)\n",
    "        self.generation_frame.grid(row=0, column=0, padx=20, pady=20)\n",
    "        self.generation_frame.grid_columnconfigure(0, weight=1)\n",
    "\n",
    "        self.image_generation_frame = customtkinter.CTkFrame(self.generation_frame)\n",
    "        self.image_generation_frame.grid(row=0, column=0, padx=20, pady=20, sticky=\"nsew\")\n",
    "        self.image_generation_frame.grid_columnconfigure(0, weight=1)\n",
    "\n",
    "        self.random_button = customtkinter.CTkButton(self.image_generation_frame, text='Random (üíª)', command = self.empty) # cursor = '@Posys_Cursor_Strokeless/Posy_Strokeless_link.cur')\n",
    "        self.random_button.grid(row = 0, column = 0, padx = 10, pady = (20, 5))\n",
    "        self.random_button.bind(\"<ButtonRelease-1>\", self.random_image)\n",
    "\n",
    "        self.random_label = customtkinter.CTkLabel(self.image_generation_frame, text = '', ) # cursor = '@Posys_Cursor_Strokeless/Posy_Strokeless.cur')\n",
    "        self.random_label.grid(row = 1, column = 0, padx = 10, pady = 5)\n",
    "\n",
    "        self.diffuse_button = customtkinter.CTkButton(self.image_generation_frame, text='Diffuse (‚Çø)', command = self.empty) # cursor = '@Posys_Cursor_Strokeless/Posy_Strokeless_link.cur')\n",
    "        self.diffuse_button.grid(row = 2, column = 0, padx = 10, pady = 5)\n",
    "        self.diffuse_button.bind(\"<ButtonRelease-1>\", self.diffuse)\n",
    "\n",
    "        self.edge_button = customtkinter.CTkButton(self.image_generation_frame, text='Edge (üíª‚è≥)', command = self.empty) # cursor = '@Posys_Cursor_Strokeless/Posy_Strokeless_link.cur')\n",
    "        self.edge_button.grid(row = 3, column = 0, padx = 10, pady = 5)\n",
    "        self.edge_button.bind(\"<ButtonRelease-1>\", self.edge)\n",
    "\n",
    "        self.control_button = customtkinter.CTkButton(self.image_generation_frame, text='Control (‚Çø)', command = self.empty) # cursor = '@Posys_Cursor_Strokeless/Posy_Strokeless_link.cur')\n",
    "        self.control_button.grid(row = 4, column = 0, padx = 10, pady = 5)\n",
    "        self.control_button.bind(\"<ButtonRelease-1>\", self.control)\n",
    "\n",
    "        self.sheeps_button = customtkinter.CTkButton(self.image_generation_frame, text='Sheeps (‚Çø)', command = self.empty)\n",
    "        self.sheeps_button.grid(row = 5, column = 0, padx = 10, pady = (5, 20))\n",
    "        self.sheeps_button.bind(\"<ButtonRelease-1>\", self.sheeps)\n",
    "\n",
    "        self.text_generation_frame = customtkinter.CTkFrame(self.generation_frame)\n",
    "        self.text_generation_frame.grid(row=1, column=0, padx=20, pady=20, sticky=\"nsew\")\n",
    "        self.text_generation_frame.grid_columnconfigure(0, weight=1)\n",
    "\n",
    "        self.switch_magic = customtkinter.CTkSwitch(self.text_generation_frame, text = 'Magic Prompt (üíª)', variable = self.magic, onvalue = 'on', offvalue = 'off')\n",
    "        self.switch_magic.grid(row = 0, column = 0, padx = 5, pady = (20, 5))\n",
    "\n",
    "        self.switch_open = customtkinter.CTkSwitch(self.text_generation_frame, text = 'Open Assistant (ü§ó)', variable = self.open, onvalue = 'on', offvalue = 'off')\n",
    "        self.switch_open.grid(row = 1, column = 0, padx = 10, pady = 5)\n",
    "\n",
    "        self.label_open = customtkinter.CTkLabel(self.text_generation_frame, text = 'Format for Open Assistant (|INPUT| will be replaced by prompt.) :')\n",
    "        self.label_open.grid(row = 2, column = 0, padx = 10, pady = (10, 0), sticky = 'w')\n",
    "        self.label_open.configure(wraplength = 250, justify = 'left')\n",
    "\n",
    "        self.textbox_open = customtkinter.CTkTextbox(self.text_generation_frame, width = 300, height = 200)\n",
    "        self.textbox_open.grid(row = 3, column = 0, padx = 10, pady = 5)\n",
    "        self.textbox_open.insert(\"0.0\", format_open_assistant)\n",
    "\n",
    "        self.generate_prompt_button = customtkinter.CTkButton(self.text_generation_frame, text='Generate Prompt', command=self.generate_prompt)\n",
    "        self.generate_prompt_button.grid(row = 4, column = 0, padx = 10, pady = 5)\n",
    "\n",
    "        self.gpt_2_generate_prompt_button = customtkinter.CTkButton(self.text_generation_frame, text='Generate Prompt with GPT-2 (üíª)', command=self.gpt_2_generate_prompt)\n",
    "        self.gpt_2_generate_prompt_button.grid(row = 5, column = 0, padx = 10, pady = (5, 20))\n",
    "\n",
    "        self.settings_frame = customtkinter.CTkScrollableFrame(self.tabview.tab(\"Settings\"), width=350, height=450)\n",
    "        self.settings_frame.grid(row=0, column=0, padx=20, pady=20)\n",
    "        self.settings_frame.grid_columnconfigure(0, weight=1)\n",
    "\n",
    "        self.color_button = customtkinter.CTkButton(self.settings_frame, text=\"Change Pen Color\", command=self.change_pen_color, ) # cursor = '@Posys_Cursor_Strokeless/Posy_Strokeless_link.cur')\n",
    "        self.color_button.grid(row = 0, column = 0, padx = 5, pady = (20, 5))\n",
    "\n",
    "        self.width_button = customtkinter.CTkButton(self.settings_frame, text=\"Change Pen Width\", command=self.change_pen_width, ) # cursor = '@Posys_Cursor_Strokeless/Posy_Strokeless_link.cur')\n",
    "        self.width_button.grid(row = 1, column = 0, padx = 5, pady = 5)\n",
    "\n",
    "        self.width_slider = customtkinter.CTkSlider(self.settings_frame, from_ = 0, to = 30, command = self.empty) # cursor = '@Posys_Cursor_Strokeless/Posy_Strokeless_link.cur')\n",
    "        self.width_slider.set(pen_width)\n",
    "        self.width_slider.bind(\"<ButtonRelease-1>\", self.change_width_slider)\n",
    "        self.width_slider.grid(row = 2, column = 0, padx = 5, pady = 5)\n",
    "\n",
    "        clear = customtkinter.CTkImage(light_image = Image.open('assets/clear_light.png'), dark_image=Image.open('assets/clear_dark.png'), size=(20, 20))\n",
    "        self.clear_button = customtkinter.CTkButton(self.settings_frame, text='Clear', image = clear, compound = 'left', command = self.empty)\n",
    "        self.clear_button.grid(row = 3, column = 0, padx = 5, pady = 5)\n",
    "        self.clear_button.bind(\"<ButtonRelease-1>\", self.clear)\n",
    "\n",
    "        self.crop_button = customtkinter.CTkCheckBox(self.settings_frame, text = 'Crop', command = self.empty) # cursor = '@Posys_Cursor_Strokeless/Posy_Strokeless_link.cur')\n",
    "        self.crop_button.bind(\"<ButtonRelease-1>\", self.crop_switch)\n",
    "        self.crop_button.grid(row = 4, column = 0, padx = 5, pady = 5)\n",
    "\n",
    "        self.separate_button = customtkinter.CTkCheckBox(self.settings_frame, text = 'Separate', command = self.empty) # cursor = '@Posys_Cursor_Strokeless/Posy_Strokeless_link.cur')\n",
    "        self.separate_button.bind(\"<ButtonRelease-1>\", self.separate_switch)\n",
    "        self.separate_button.grid(row = 5, column = 0, padx = 5, pady = 5)\n",
    "\n",
    "        reset = customtkinter.CTkImage(light_image = Image.open('assets/reset_light.png'), dark_image=Image.open('assets/reset_dark.png'), size=(20, 20))\n",
    "        self.reset_button = customtkinter.CTkButton(self.settings_frame, text='Reset', image =  reset, compound = 'left', command = self.empty)\n",
    "        self.reset_button.grid(row = 6, column = 0, padx = 5, pady = 5)\n",
    "        self.reset_button.bind(\"<ButtonRelease-1>\", self.reset)\n",
    "\n",
    "        lock = customtkinter.CTkImage(light_image = Image.open('assets/lock_light.png'), dark_image=Image.open('assets/lock_dark.png'), size=(20, 20))\n",
    "        self.lock_button = customtkinter.CTkButton(self.settings_frame, text='Lock', image = lock, compound = 'left', command = self.empty)\n",
    "        self.lock_button.grid(row = 7, column = 0, padx = 5, pady = 5)\n",
    "        self.lock_button.bind(\"<ButtonRelease-1>\", self.lock)\n",
    "\n",
    "        upload = customtkinter.CTkImage(light_image = Image.open('assets/upload_light.png'), dark_image=Image.open('assets/upload_dark.png'), size=(20, 20))\n",
    "        self.upload_button = customtkinter.CTkButton(self.settings_frame, text = 'Upload', command = self.upload, image = upload, compound = 'left')\n",
    "        self.upload_button.grid(row = 8, column = 0, padx = 5, pady = 5)\n",
    "\n",
    "        download = customtkinter.CTkImage(light_image = Image.open('assets/download_light.png'), dark_image=Image.open('assets/download_dark.png'), size=(20, 20))\n",
    "        self.download_button = customtkinter.CTkButton(self.settings_frame, text = 'Download', command = self.download, image = download, compound = 'left')\n",
    "        self.download_button.grid(row = 9, column = 0, padx = 5, pady = 5)\n",
    "\n",
    "        undo = customtkinter.CTkImage(light_image = Image.open('assets/undo_light.png'), dark_image=Image.open('assets/undo_dark.png'), size=(20, 20))\n",
    "        self.undo_button = customtkinter.CTkButton(self.settings_frame, text = 'Undo', image = undo, compound = 'left', command = self.empty)\n",
    "        self.undo_button.grid(row = 10, column = 0, padx = 5, pady = 5)\n",
    "        self.undo_button.bind(\"<ButtonRelease-1>\", self.undo)\n",
    "\n",
    "        redo = customtkinter.CTkImage(light_image = Image.open('assets/redo_light.png'), dark_image=Image.open('assets/redo_dark.png'), size=(20, 20))\n",
    "        self.redo_button = customtkinter.CTkButton(self.settings_frame, text = 'Redo', image = redo, compound = 'left', command = self.empty)\n",
    "        self.redo_button.grid(row = 11, column = 0, padx = 5, pady = (5,20))\n",
    "        self.redo_button.bind(\"<ButtonRelease-1>\", self.redo)\n",
    "\n",
    "        # set default values\n",
    "        self.appearance_mode_optionemenu.set(\"Dark\")\n",
    "        self.scaling_optionemenu.set(\"100%\")\n",
    "    \n",
    "    def empty(self):\n",
    "        pass\n",
    "\n",
    "    def change_appearance_mode_event(self, new_appearance_mode: str):\n",
    "        customtkinter.set_appearance_mode(new_appearance_mode)\n",
    "    \n",
    "    def change_theme_event(self, new_theme: str):\n",
    "        customtkinter.set_default_color_theme(new_theme)\n",
    "        self.destroy()\n",
    "        app = App()\n",
    "        app.mainloop()\n",
    "\n",
    "    def change_scaling_event(self, new_scaling: str):\n",
    "        new_scaling_float = int(new_scaling.replace(\"%\", \"\")) / 100\n",
    "        customtkinter.set_widget_scaling(new_scaling_float)\n",
    "    \n",
    "    def change_pen_color(self):\n",
    "        global pen_color\n",
    "        color = colorchooser.askcolor()[1]\n",
    "        if color:\n",
    "            pen_color = color\n",
    "    \n",
    "    def change_pen_width(self):\n",
    "        global pen_width\n",
    "        width = simpledialog.askinteger(\"Pen Width\", \"Enter the new pen width:\", initialvalue=pen_width)\n",
    "        if width:\n",
    "            pen_width = int(width)\n",
    "    \n",
    "    def change_width_slider(self, event):\n",
    "        global pen_width\n",
    "        pen_width = int(self.width_slider.get())\n",
    "\n",
    "    def classify_image(self, event):\n",
    "        global auto_text\n",
    "        # Convert the drawn image to a numpy array\n",
    "\n",
    "        if self.separate.get() != 1:\n",
    "            image = subprocess_image(np.array(img.convert('L')))\n",
    "            if self.crop.get() == 1:\n",
    "                image += 1\n",
    "                image[np.round(image.copy(), 1) == 2.0] = 0\n",
    "                image = crop3(image)\n",
    "                image[image == 0.0] = 1\n",
    "                image -= 1\n",
    "                image[image == 0.0] = 1\n",
    "\n",
    "                width, height = image.shape\n",
    "\n",
    "                if (width != 0) and (height != 0):\n",
    "                    if width > height:\n",
    "                        new_width = 90\n",
    "                        new_height = int((90/width) * height)\n",
    "                    else:\n",
    "                        new_height = 90\n",
    "                        new_width = int((90/height) * width)\n",
    "\n",
    "                    image = resize(image, (new_width, new_height), anti_aliasing = True)\n",
    "\n",
    "                image = np.pad(image, pad_width=((math.ceil(((resize_size[0]) - image.shape[0])/2.0),math.floor(((resize_size[0]) - image.shape[0])/2.0)), (math.ceil(((resize_size[1]) - image.shape[1])/2.0),math.floor(((resize_size[1]) - image.shape[1])/2.0))), mode='constant', constant_values=1)\n",
    "\n",
    "                image = np.clip(image, 0, 1)\n",
    "            \n",
    "            #ipyplot.plot_images([image])\n",
    "\n",
    "            # Make a prediction with your CNN model\n",
    "            yhat = cnn_model.predict(np.expand_dims(np.expand_dims(image, 2), 0))\n",
    "            # Display the prediction\n",
    "            self.prediction_label.configure(text = decode(yhat))\n",
    "            self.best_label.configure(text = 'Prediction: ' + encoder.inverse_transform(yhat)[0]) #+ ' (' + str(round(np.max(yhat)*100, 2)) + '%)')\n",
    "            \n",
    "            \n",
    "            if auto_text:\n",
    "                self.prompt_entry.delete(0, END)\n",
    "                self.prompt_entry.insert(0, encoder.inverse_transform(yhat)[0])\n",
    "        else:\n",
    "            image = np.array(img.convert('L'))\n",
    "            images = separate_images(image)\n",
    "            if images == None:\n",
    "                self.best_label.configure(text = 'Predictions: ')\n",
    "                if auto_text:\n",
    "                    self.prompt_entry.delete(0, END)\n",
    "                    self.prompt_entry.insert(0, '')\n",
    "                return\n",
    "            predictions = []\n",
    "            for image in images:\n",
    "                width, height = image.shape\n",
    "\n",
    "                if (width != 0) and (height != 0):\n",
    "                    if width > height:\n",
    "                        new_width = 90\n",
    "                        new_height = int((90/width) * height)\n",
    "                    else:\n",
    "                        new_height = 90\n",
    "                        new_width = int((90/height) * width)\n",
    "\n",
    "                    image = resize(image, (new_width, new_height), anti_aliasing = True)\n",
    "                \n",
    "                image = np.pad(image, pad_width=((math.ceil(((resize_size[0]) - image.shape[0])/2.0),math.floor(((resize_size[0]) - image.shape[0])/2.0)), (math.ceil(((resize_size[1]) - image.shape[1])/2.0),math.floor(((resize_size[1]) - image.shape[1])/2.0))), mode='constant', constant_values=1)\n",
    "                image = np.clip(image, 0, 1)\n",
    "                #ipyplot.plot_images([image])\n",
    "                # image = resize(image, resize_size, anti_aliasing=True)\n",
    "                yhat = cnn_model.predict(np.expand_dims(np.expand_dims(image, 2), 0))\n",
    "                predictions.append(encoder.inverse_transform(yhat)[0])\n",
    "            # prediction_label.config(text = decode(yhat))\n",
    "            self.best_label.configure(text = 'Predictions: ' + ', '.join(predictions))\n",
    "\n",
    "            if auto_text:\n",
    "                self.prompt_entry.delete(0, END)\n",
    "                self.prompt_entry.insert(0, ', '.join(predictions))\n",
    "    \n",
    "    def clear(self, event):\n",
    "        self.line_drawer.clear(event)    \n",
    "    \n",
    "    def random_image(self, event):\n",
    "        # Get a random name\n",
    "        random_name = random.choice(random_names)\n",
    "\n",
    "        # Get a random drawing\n",
    "        random_image = qd.get_drawing(random_name)\n",
    "\n",
    "        random_image = unprocess_array(preprocess_image(random_image))\n",
    "\n",
    "        random_image = ImageOps.fit(random_image, (canvas_width, canvas_height), Image.LANCZOS)\n",
    "\n",
    "        # canvas.image = ImageTk.PhotoImage(random_image)\n",
    "        # canvas.create_image(0, 0, anchor='nw', image=canvas.image)\n",
    "        img.paste(random_image)\n",
    "        update_canvas()\n",
    "        self.classify_image(event)\n",
    "        self.random_label.configure(text = random_name)\n",
    "    \n",
    "    def crop_switch(self, event):\n",
    "        if self.crop.get() == 1:\n",
    "            self.crop.set(0)\n",
    "        else:\n",
    "            self.crop.set(1)\n",
    "        self.classify_image(event)\n",
    "    \n",
    "    def separate_switch(self, event):\n",
    "        if self.separate.get() == 1:\n",
    "            self.separate.set(0)\n",
    "        else:\n",
    "            self.separate.set(1)\n",
    "        self.classify_image(event)\n",
    "    \n",
    "    def diffuse(self, event):\n",
    "        global img\n",
    "        image = subprocess_image(np.array(img.convert('L')))\n",
    "        yhat = cnn_model.predict(np.expand_dims(np.expand_dims(image, 2), 0))\n",
    "        prediction = encoder.inverse_transform(yhat)[0]\n",
    "\n",
    "        resized_image = ImageOps.fit(img, (800, 800), Image.LANCZOS)\n",
    "\n",
    "        print(self.prompt_entry.get())\n",
    "        output = diffuser(prompt = self.prompt_entry.get(), image = open(save_input(resized_image, self.prompt_entry.get()), 'rb'))\n",
    "        url = output[0]\n",
    "        print(url)\n",
    "\n",
    "        response = requests.get(url)\n",
    "        save_output(response, self.prompt_entry.get())\n",
    "        output_image = Image.open(io.BytesIO(response.content))\n",
    "        output_image = ImageOps.fit(output_image, (canvas_width, canvas_height), Image.LANCZOS)\n",
    "\n",
    "        # Draw the image on the canvas\n",
    "        # canvas.image = ImageTk.PhotoImage(output_image)\n",
    "        # canvas.create_image(0, 0, anchor='nw', image=canvas.image)\n",
    "\n",
    "        # set output to img\n",
    "        img.paste(output_image)\n",
    "\n",
    "        update_canvas()\n",
    "    \n",
    "    def edge(self, event):\n",
    "        global img\n",
    "        image = ImageOps.fit(img, (800, 800), Image.LANCZOS)\n",
    "        edge = edge_map(caption = self.prompt_entry.get(), vae = 'runwayml/stable-diffusion-v1-5', device = 'cpu', unet = 'runwayml/stable-diffusion-v1-5', lgp_path = 'SDv1.5-trained_LGP.pt', strength = 0.3, img_path = save_input(image, self.prompt_entry.get()))\n",
    "\n",
    "        edge= ImageOps.fit(edge, (canvas_width, canvas_height), Image.LANCZOS)\n",
    "        # canvas.image = ImageTk.PhotoImage(edge)\n",
    "        # canvas.create_image(0, 0, anchor='nw', image=canvas.image)\n",
    "        img.paste(edge)\n",
    "        update_canvas()\n",
    "    \n",
    "    def control(self, event):\n",
    "        global img\n",
    "        image = subprocess_image(np.array(img.convert('L')))\n",
    "        yhat = cnn_model.predict(np.expand_dims(np.expand_dims(image, 2), 0))\n",
    "        prediction = encoder.inverse_transform(yhat)[0]\n",
    "\n",
    "        resized_image = ImageOps.fit(img, (800, 800), Image.LANCZOS)\n",
    "\n",
    "        print(self.prompt_entry.get())\n",
    "        output = controlnet(image = open(save_input(resized_image, self.prompt_entry.get()), 'rb'), prompt = self.prompt_entry.get())\n",
    "        url = output[1]\n",
    "        print(url)\n",
    "\n",
    "        response = requests.get(url)\n",
    "        save_output(response, self.prompt_entry.get())\n",
    "        output_image = Image.open(io.BytesIO(response.content))\n",
    "        output_image = ImageOps.fit(output_image, (canvas_width, canvas_height), Image.LANCZOS)\n",
    "\n",
    "        # Draw the image on the canvas\n",
    "        # canvas.image = ImageTk.PhotoImage(output_image)\n",
    "        # canvas.create_image(0, 0, anchor='nw', image=canvas.image)\n",
    "\n",
    "        # set output to img\n",
    "        img.paste(output_image)\n",
    "        update_canvas()\n",
    "    \n",
    "    def sheeps(self, event):\n",
    "        global img\n",
    "        image = subprocess_image(np.array(img.convert('L')))\n",
    "        yhat = cnn_model.predict(np.expand_dims(np.expand_dims(image, 2), 0))\n",
    "        prediction = encoder.inverse_transform(yhat)[0]\n",
    "\n",
    "        resized_image = ImageOps.fit(img, (800, 800), Image.LANCZOS)\n",
    "\n",
    "        print(self.prompt_entry.get())\n",
    "        output = sheepscontrol(image = open(save_input(resized_image, self.prompt_entry.get()), 'rb'), prompt = self.prompt_entry.get())\n",
    "        url = output\n",
    "        print(url)\n",
    "\n",
    "        response = requests.get(url)\n",
    "        save_output(response, self.prompt_entry.get())\n",
    "        output_image = Image.open(io.BytesIO(response.content))\n",
    "        output_image = ImageOps.fit(output_image, (canvas_width, canvas_height), Image.LANCZOS)\n",
    "\n",
    "        # Draw the image on the canvas\n",
    "        # canvas.image = ImageTk.PhotoImage(output_image)\n",
    "        # canvas.create_image(0, 0, anchor='nw', image=canvas.image)\n",
    "\n",
    "        # set output to img\n",
    "        img.paste(output_image)\n",
    "        update_canvas()\n",
    "\n",
    "    def generate_prompt(self):\n",
    "        if self.prompt_entry.get() != '':\n",
    "            if (self.magic.get() == 'on') & (self.open.get() == 'on'):\n",
    "                string = self.prompt_entry.get()\n",
    "                self.prompt_entry.delete(0, END)\n",
    "                self.prompt_entry.insert(0, create_prompt(string))\n",
    "            elif (self.magic.get() == 'on') & (self.open.get() == 'off'):\n",
    "                string = self.prompt_entry.get()\n",
    "                string = re.sub(rf'{regex_magic_prompt}', '', string)\n",
    "                string = f'{string},'\n",
    "                self.prompt_entry.delete(0, END)\n",
    "                self.prompt_entry.insert(0, magic_prompt_generator(string))\n",
    "            elif (self.magic.get() == 'off') & (self.open.get() == 'on'):\n",
    "                string = self.prompt_entry.get()\n",
    "                self.prompt_entry.delete(0, END)\n",
    "                self.prompt_entry.insert(0, open_assistant_generator(string))\n",
    "    \n",
    "    def gpt_2_generate_prompt(self):\n",
    "        string = self.prompt_entry.get()\n",
    "        string = re.sub(rf'{regex_magic_prompt}', '', string)\n",
    "        string = f'{string},'\n",
    "        self.prompt_entry.delete(0, END)\n",
    "        self.prompt_entry.insert(0, gpt_2_generator(string))\n",
    "\n",
    "    def prompt_changed(self, event):\n",
    "        global auto_text\n",
    "        auto_text = False\n",
    "        if self.prompt_entry.get() == '':\n",
    "            auto_text = True\n",
    "    \n",
    "    def reset(self, event):\n",
    "        global auto_text\n",
    "        auto_text = True\n",
    "        self.classify_image(event)\n",
    "    \n",
    "    def lock(self, event):\n",
    "        global auto_text\n",
    "        auto_text = False\n",
    "    \n",
    "    def upload(self):\n",
    "        file_path = filedialog.askopenfilename()\n",
    "        if file_path:\n",
    "            image = Image.open(file_path)\n",
    "            image = ImageOps.fit(image, (canvas_width, canvas_height), Image.LANCZOS)\n",
    "            # canvas.image = ImageTk.PhotoImage(image)\n",
    "            # canvas.create_image(0, 0, anchor='nw', image=canvas.image)\n",
    "            img.paste(image)\n",
    "            update_canvas()\n",
    "    \n",
    "    def download(self):\n",
    "        file_path = filedialog.asksaveasfilename(defaultextension = [('PNG', '*.png'), ('JPG', '*.jpg')], filetypes = [('PNG', '*.png'), ('JPG', '*.jpg')])\n",
    "        if file_path:\n",
    "            img.save(file_path)\n",
    "    \n",
    "    def undo(self, event):\n",
    "        self.line_drawer.undo(event)\n",
    "\n",
    "    def redo(self, event):\n",
    "        self.line_drawer.redo(event)\n",
    "if __name__ == \"__main__\":\n",
    "    app = App()\n",
    "    app.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "search_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
