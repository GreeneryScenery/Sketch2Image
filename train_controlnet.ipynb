{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "XoFs2Jbh9_f2",
        "BZp5u3iK93T1",
        "wgaQ4s1X97Vb",
        "uVjcdvVIw7V7"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up"
      ],
      "metadata": {
        "id": "XoFs2Jbh9_f2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub einops transformers xformers open_clip_torch omegaconf pytorch_lightning"
      ],
      "metadata": {
        "id": "O6ewKL1r2RMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "KeNWYoJM3-Bk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('models'):\n",
        "    os.mkdir('models')"
      ],
      "metadata": {
        "id": "iv-49Je33_sg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "downloaded_model_path = hf_hub_download(repo_id=\"stabilityai/stable-diffusion-2-1-base\", filename=\"v2-1_512-ema-pruned.ckpt\", local_dir = 'models')\n",
        "print(downloaded_model_path)"
      ],
      "metadata": {
        "id": "qCCB7fe63EB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/lllyasviel/ControlNet.git"
      ],
      "metadata": {
        "id": "nsS0i0M2yrnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFvzHUNaW4Lk"
      },
      "outputs": [],
      "source": [
        "!gdown 1P2kb1SCqnZrK_P32Vmcf5FShjbC9kN7e"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xf \"Object.tar\""
      ],
      "metadata": {
        "id": "1VHLtYcWW7OP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating prompts"
      ],
      "metadata": {
        "id": "BZp5u3iK93T1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import re\n",
        "import random"
      ],
      "metadata": {
        "id": "PRmUpkU_-KBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer_magic_prompt = AutoTokenizer.from_pretrained(\"Gustavosta/MagicPrompt-Stable-Diffusion\")\n",
        "model_magic_prompt = AutoModelForCausalLM.from_pretrained(\"Gustavosta/MagicPrompt-Stable-Diffusion\")"
      ],
      "metadata": {
        "id": "eugFCAny9yCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regex_magic_prompt = \"[\\[\\]']+\""
      ],
      "metadata": {
        "id": "_NjZbYgp9zEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def magic_prompt_generator(string, length):\n",
        "    input_magic_prompt = tokenizer_magic_prompt.encode(string, return_tensors='pt')\n",
        "    output_magic_prompt = model_magic_prompt.generate(input_magic_prompt, max_length=100, do_sample=True, top_k=50, top_p=0.95, temperature=0.5, num_return_sequences=length)\n",
        "    return output_magic_prompt"
      ],
      "metadata": {
        "id": "7sJNmaeK92Mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "format_open_assistant = '<|prompter|>Please form a sentence describing an image using these words: |INPUT|. This sentence will be used for image generation in ControlNet and Stable Diffusion so be as descriptive and creative as possible, while not adding too much extra stuff.<|endoftext|><|assistant|>'"
      ],
      "metadata": {
        "id": "bWrbVQNO-EII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "API_URL = \"https://api-inference.huggingface.co/models/OpenAssistant/oasst-sft-1-pythia-12b\"\n",
        "headers = {\"Authorization\": \"Bearer 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\"}\n",
        "\n",
        "def query(payload):\n",
        "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
        "\treturn response.json()"
      ],
      "metadata": {
        "id": "IR0ovtux-HHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def open_assistant_generator(string):\n",
        "    text_open_assistant = format_open_assistant.replace('|INPUT|', string)\n",
        "    output = query({\n",
        "        \"inputs\": text_open_assistant\n",
        "    })\n",
        "    output = output[0]['generated_text']\n",
        "    print(output)\n",
        "    return output.replace(text_open_assistant, '')"
      ],
      "metadata": {
        "id": "6wcmlxcE-NYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['sky', 'grass', 'water', 'fence', 'sun', 'day', 'light', 'single', 'eating', 'front-view', 'side-view', 'background', 'foreground', 'field', 'trees', 'clouds', 'lone', 'realistic', 'photorealistic']"
      ],
      "metadata": {
        "id": "HJKPwynmFpWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_queries(string, length, max_length):\n",
        "    queries = []\n",
        "    for i in range(max_length):\n",
        "        word_list = [string] + (random.sample(words, k = random.randint(0, 3)))\n",
        "        query = open_assistant_generator(str(word_list))\n",
        "        queries.append(query)\n",
        "    return queries"
      ],
      "metadata": {
        "id": "YnG9Q2wkQbjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_text_magic_prompt(string, max_length):\n",
        "    string = re.sub(rf'{regex_magic_prompt}', '', string)\n",
        "    string = f'{string},'\n",
        "    text_magic_prompt = magic_prompt_generator(string, max_length)\n",
        "    return text_magic_prompt"
      ],
      "metadata": {
        "id": "raTJ76dT-Oya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_text_magic_prompt(text_magic_prompt, length, max_length):\n",
        "    f = open('sheep_text_magic_prompt.txt','w')\n",
        "    for i in range(length):\n",
        "        magic_prompt = tokenizer_magic_prompt.decode(text_magic_prompt[random.randint(0, max_length - 1)], skip_special_tokens=True).replace('\\n', '')\n",
        "        f.write(magic_prompt + '\\n')\n",
        "    f.close()"
      ],
      "metadata": {
        "id": "UXf6u03QSFcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_prompts(queries, text_magic_prompt, length, max_length):\n",
        "    prompts = []\n",
        "    for i in range(length):\n",
        "        prompt = random.choice(queries)\n",
        "        magic_prompt = text_magic_prompt[random.randint(0, max_length - 1)]\n",
        "        prompt = prompt + ' ' + magic_prompt\n",
        "        prompts.append(prompt.replace('\\n', ''))\n",
        "    return prompts"
      ],
      "metadata": {
        "id": "Xg7hH7jUQqw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating dataset"
      ],
      "metadata": {
        "id": "wgaQ4s1X97Vb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# directory_GT = 'Object/GT/train/20'\n",
        "# directory_Sketch = 'Object/Sketch/train/20'"
      ],
      "metadata": {
        "id": "ZqNXSQ_ZCThr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory_GT = 'Object/GT/train'\n",
        "directory_Sketch = 'Object/Sketch/train'"
      ],
      "metadata": {
        "id": "hBhIOmNHO4vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "names_dict = {'2': 'Bicycle', '3': 'Car', '4': 'Motorcycle', '5': 'Airplane', '10': 'Traffic light', '11': 'Fire hydrant', '17': 'Cat', '18': 'Dog', '19': 'Horse', '20': 'Sheep', '21': 'Cow', '22': 'Elephant', '24': 'Zebra', '25': 'Giraffe'}"
      ],
      "metadata": {
        "id": "CmWsFv3sPnGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "data = []\n",
        "conditioning_image = []\n",
        "image = []\n",
        "\n",
        "for folder in os.listdir(directory_GT):\n",
        "    for filename in os.listdir(f'{directory_GT}/{folder}'):\n",
        "      if not filename.startswith('._'):\n",
        "          f_Sketch = os.path.join(f'{directory_Sketch}/{folder}', filename)\n",
        "          f_GT = os.path.join(f'{directory_GT}/{folder}', filename)\n",
        "          \n",
        "          dictionary = dict()\n",
        "          dictionary['text'] = f'{names_dict[folder]}'\n",
        "\n",
        "          if os.path.isfile(f_Sketch):\n",
        "              # i = PIL.Image.open(f_Sketch).convert('RGB').resize((256, 256))\n",
        "              c = cv2.imread(f_Sketch)\n",
        "              c = cv2.cvtColor(c, cv2.COLOR_BGR2RGB)\n",
        "              c = cv2.resize(c, (256, 256))\n",
        "              cv2.imwrite(f'conditioning_images/{filename}', c)\n",
        "              conditioning_image.append(c)\n",
        "              dictionary['conditioning_image'] = f'conditioning_images/{filename}'\n",
        "          if os.path.isfile(f_GT):\n",
        "              # c = PIL.Image.open(f_GT).convert('RGB').resize((256, 256))\n",
        "              i = cv2.imread(f_GT)\n",
        "              i = cv2.cvtColor(i, cv2.COLOR_BGR2RGB)\n",
        "              \n",
        "              h, w = i.shape[:2]\n",
        "              if h > w:\n",
        "                  new_h = 256\n",
        "                  new_w = int(w * new_h / h)\n",
        "              else:\n",
        "                  new_w = 256\n",
        "                  new_h = int(h * new_w / w)\n",
        "              i = cv2.resize(i, (new_w, new_h))\n",
        "\n",
        "              # Pad the shorter side to 256 pixels\n",
        "              top = bottom = left = right = 0\n",
        "              if new_h < new_w:\n",
        "                  diff = new_w - new_h\n",
        "                  top = diff // 2\n",
        "                  bottom = diff - top\n",
        "              else:\n",
        "                  diff = new_h - new_w\n",
        "                  left = diff // 2\n",
        "                  right = diff - left\n",
        "              i = cv2.copyMakeBorder(i, top, bottom, left, right, cv2.BORDER_CONSTANT, value=(255.0, 255.0, 255.0))\n",
        "\n",
        "              cv2.imwrite(f'images/{filename}', i)\n",
        "              image.append(i)\n",
        "              dictionary['image'] = f'images/{filename}'\n",
        "          \n",
        "          json_data = json.dumps(dictionary)\n",
        "          data.append(json.loads(json_data))"
      ],
      "metadata": {
        "id": "Jah4u3TkQlii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "mo5piCq_Tts9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('train.jsonl', 'w') as outfile:\n",
        "    for entry in data:\n",
        "        json.dump(entry, outfile)\n",
        "        outfile.write('\\n')"
      ],
      "metadata": {
        "id": "VGtHP8zISYzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "id": "ydQ1vyQFXSQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "b6nDRIPHPkfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import HfApi\n",
        "api = HfApi()"
      ],
      "metadata": {
        "id": "jxFhT2bVPNxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api.upload_file(\n",
        "    path_or_fileobj=\"train.jsonl\",\n",
        "    path_in_repo=\"train.jsonl\",\n",
        "    repo_id=\"GreeneryScenery/SheepsNetV2\",\n",
        "    repo_type=\"dataset\",\n",
        ")"
      ],
      "metadata": {
        "id": "tMbv6dr2QaQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r images.zip images\n",
        "!zip -r conditioning_images.zip conditioning_images"
      ],
      "metadata": {
        "id": "kiff6O0zTZsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api.upload_file(\n",
        "    path_or_fileobj=\"images.zip\",\n",
        "    path_in_repo=\"images.zip\",\n",
        "    repo_id=\"GreeneryScenery/SheepsNetV2\",\n",
        "    repo_type=\"dataset\",\n",
        ")"
      ],
      "metadata": {
        "id": "EM6KIDTDQarq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api.upload_file(\n",
        "    path_or_fileobj=\"conditioning_images.zip\",\n",
        "    path_in_repo=\"conditioning_images.zip\",\n",
        "    repo_id=\"GreeneryScenery/SheepsNetV2\",\n",
        "    repo_type=\"dataset\",\n",
        ")"
      ],
      "metadata": {
        "id": "MgZ8DehqQf2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# text_magic_prompt = create_text_magic_prompt('sheep', 100)"
      ],
      "metadata": {
        "id": "eYwQFljfM2kg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save_text_magic_prompt(text_magic_prompt, len(os.listdir(directory_GT)), 100)"
      ],
      "metadata": {
        "id": "f7elc0zVSnNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# text_magic_prompt = open('sheep_text_magic_prompt.txt', 'r').read().split('\\n')"
      ],
      "metadata": {
        "id": "bjPNpyDMUrXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# queries = create_queries('sheep', len(os.listdir(directory_GT)), 50)"
      ],
      "metadata": {
        "id": "mA2Jxqw1TE-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list_prompts = create_prompts(queries, text_magic_prompt, len(os.listdir(directory_GT)), 100)\n",
        "# list_prompts"
      ],
      "metadata": {
        "id": "RA6JBHEjGFwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# f = open('sheep_prompts.txt','w')\n",
        "# for prompt in list_prompts:\n",
        "#   f.write(prompt + '\\n')\n",
        "# f.close()"
      ],
      "metadata": {
        "id": "1zv5NbvpGO46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = open('sheep_prompts_edited.txt', 'r').read().split('\\n')"
      ],
      "metadata": {
        "id": "dwcwTnPEJN7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# j = open('train.jsonl', 'r').read().split('\\n')"
      ],
      "metadata": {
        "id": "c1ZSiTn0mAFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import json\n",
        "\n",
        "# with open('train.jsonl', 'r') as json_file:\n",
        "#     json_list = list(json_file)\n",
        "\n",
        "# with open('train2.jsonl', 'w') as outfile:\n",
        "#     for json_str in json_list:\n",
        "#         result = json.loads(json_str)\n",
        "#         result['text'] = 'A photorealistic single sheep standing in a realistic field with background removed. sheep, trending on artstation, artstationHD, artstationHQ, patreon, 4k, 8k'\n",
        "#         json.dump(result, outfile)\n",
        "#         outfile.write('\\n')"
      ],
      "metadata": {
        "id": "6hinFRKDmnxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import csv\n",
        "# import PIL\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "# import os"
      ],
      "metadata": {
        "id": "f4lfHjCXC3UX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# conditioning_image = []\n",
        "# image = []\n",
        "\n",
        "# for filename in os.listdir(directory_GT):\n",
        "#     if not filename.startswith('._'):\n",
        "#         f_Sketch = os.path.join(directory_Sketch, filename)\n",
        "#         f_GT = os.path.join(directory_GT, filename)\n",
        "        \n",
        "#         if os.path.isfile(f_Sketch):\n",
        "#             # i = PIL.Image.open(f_Sketch).convert('RGB').resize((256, 256))\n",
        "#             i = cv2.imread(f_Sketch)\n",
        "#             i = cv2.cvtColor(i, cv2.COLOR_BGR2RGB)\n",
        "#             i = cv2.resize(i, (256, 256))\n",
        "#             cv2.imwrite(f'i/{filename}', i)\n",
        "#             conditioning_image.append(i)\n",
        "#         if os.path.isfile(f_GT):\n",
        "#             # c = PIL.Image.open(f_GT).convert('RGB').resize((256, 256))\n",
        "#             c = cv2.imread(f_GT)\n",
        "#             c = cv2.cvtColor(c, cv2.COLOR_BGR2RGB)\n",
        "            \n",
        "#             h, w = c.shape[:2]\n",
        "#             if h > w:\n",
        "#                 new_h = 256\n",
        "#                 new_w = int(w * new_h / h)\n",
        "#             else:\n",
        "#                 new_w = 256\n",
        "#                 new_h = int(h * new_w / w)\n",
        "#             c = cv2.resize(c, (new_w, new_h))\n",
        "\n",
        "#             # Pad the shorter side to 256 pixels\n",
        "#             top = bottom = left = right = 0\n",
        "#             if new_h < new_w:\n",
        "#                 diff = new_w - new_h\n",
        "#                 top = diff // 2\n",
        "#                 bottom = diff - top\n",
        "#             else:\n",
        "#                 diff = new_h - new_w\n",
        "#                 left = diff // 2\n",
        "#                 right = diff - left\n",
        "#             c = cv2.copyMakeBorder(c, top, bottom, left, right, cv2.BORDER_CONSTANT, value=(255.0, 255.0, 255.0))\n",
        "\n",
        "#             cv2.imwrite(f'c/{filename}', c)\n",
        "#             image.append(c)"
      ],
      "metadata": {
        "id": "LY7M6TSoDM91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install ipyplot"
      ],
      "metadata": {
        "id": "-uEHWjpQGnVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import ipyplot"
      ],
      "metadata": {
        "id": "bxGzAlF4GpTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ipyplot.plot_images(image, max_images = 10)"
      ],
      "metadata": {
        "id": "X8Hbx2tDGk6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install ipyplot"
      ],
      "metadata": {
        "id": "3EdQutBALHJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import ipyplot\n",
        "# ipyplot.plot_images(image)"
      ],
      "metadata": {
        "id": "rz9qaEM0LNQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.DataFrame({'image': image, 'conditioning_image': conditioning_image, 'text': ['A sheep with background removed from this sketch image.'] * len(image)})\n",
        "# df"
      ],
      "metadata": {
        "id": "J3R0XIfFGzrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.to_csv('SheepsNet.csv', index = False)"
      ],
      "metadata": {
        "id": "xVAPECLdHYQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !zip -r image.zip Object/GT/train/20"
      ],
      "metadata": {
        "id": "pW4oO_Y2OY4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !zip -r conditioning_image.zip Object/Sketch/train/20"
      ],
      "metadata": {
        "id": "5KKxd56HOs35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !zip -r images.zip i\n",
        "# !zip -r conditioning_images.zip c"
      ],
      "metadata": {
        "id": "jr4EBxkHJefU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data = []\n",
        "# i = 0\n",
        "# for filename in os.listdir(directory_GT):\n",
        "#     if not filename.startswith('._'):\n",
        "#         f_Sketch = os.path.join(directory_Sketch, filename)\n",
        "#         f_GT = os.path.join(directory_GT, filename)\n",
        "#         dictionary = dict()\n",
        "        \n",
        "#         dictionary['text'] = text[i]\n",
        "#         if os.path.isfile(f_Sketch):\n",
        "#             dictionary['conditioning_image'] = f'conditioning_images/{filename}'\n",
        "#         if os.path.isfile(f_GT):\n",
        "#             dictionary['image'] = f'images/{filename}'\n",
        "#         json_data = json.dumps(dictionary)\n",
        "#         data.append(json.loads(json_data))\n",
        "#     i += 1\n",
        "# data"
      ],
      "metadata": {
        "id": "a39F1WtXQQdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with open('train.jsonl', 'w') as outfile:\n",
        "#     for entry in data:\n",
        "#         json.dump(entry, outfile)\n",
        "#         outfile.write('\\n')"
      ],
      "metadata": {
        "id": "XbVCbgMUQJWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import cv2\n",
        "# import numpy as np\n",
        "# import json\n",
        "\n",
        "# from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "# class MyDataset(Dataset):\n",
        "#     def __init__(self):\n",
        "#         self.data = []\n",
        "#         # with open('./training/fill50k/prompt.json', 'rt') as f:\n",
        "#         #     for line in f:\n",
        "#         #         self.data.append(json.loads(line))\n",
        "\n",
        "#         i = 0\n",
        "#         for filename in os.listdir(directory_GT):\n",
        "#             f_Sketch = os.path.join(directory_Sketch, filename)\n",
        "#             f_GT = os.path.join(directory_GT, filename)\n",
        "#             dictionary = dict()\n",
        "            \n",
        "#             if os.path.isfile(f_Sketch):\n",
        "#                 dictionary['source'] = f_Sketch\n",
        "#             if os.path.isfile(f_GT):\n",
        "#                 dictionary['target'] = f_GT\n",
        "#             dictionary['prompt'] = list_prompts[i]\n",
        "#             json_data = json.dumps(dictionary)\n",
        "#             self.data.append(json.loads(json_data))\n",
        "#             i += 1\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.data)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         item = self.data[idx]\n",
        "\n",
        "#         source_filename = item['source']\n",
        "#         target_filename = item['target']\n",
        "#         prompt = item['prompt']\n",
        "\n",
        "#         source = cv2.imread(source_filename)\n",
        "#         target = cv2.imread(target_filename)\n",
        "\n",
        "#         # Do not forget that OpenCV read images in BGR order.\n",
        "#         source = cv2.cvtColor(source, cv2.COLOR_BGR2RGB)\n",
        "#         target = cv2.cvtColor(target, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "#         target = cv2.resize(target, (256, 256))\n",
        "\n",
        "#         # Normalize source images to [0, 1].\n",
        "#         source = source.astype(np.float32) / 255.0\n",
        "\n",
        "#         # Normalize target images to [-1, 1].\n",
        "#         target = (target.astype(np.float32) / 127.5) - 1.0\n",
        "\n",
        "#         return dict(jpg=target, txt=prompt, hint=source, a = target_filename)"
      ],
      "metadata": {
        "id": "qR8CnQcqZA4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset = MyDataset()\n",
        "# print(len(dataset))\n",
        "\n",
        "# item = dataset[1234]\n",
        "# jpg = item['jpg']\n",
        "# txt = item['txt']\n",
        "# hint = item['hint']\n",
        "# a = item['a']\n",
        "# print(txt)\n",
        "# print(jpg.shape)\n",
        "# print(hint.shape)\n",
        "# print(a)"
      ],
      "metadata": {
        "id": "xy-U2q6pjZVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train ControlNet"
      ],
      "metadata": {
        "id": "uVjcdvVIw7V7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/huggingface/diffusers\n",
        "%cd diffusers\n",
        "!pip install -e ."
      ],
      "metadata": {
        "id": "aBkTu2Lt0jMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r examples/controlnet/requirements.txt"
      ],
      "metadata": {
        "id": "20NLeDzG1C2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xformers"
      ],
      "metadata": {
        "id": "FQbL4a-K4soX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "jnymGrhJ1jT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate config default"
      ],
      "metadata": {
        "id": "TcakrAVH1M73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from accelerate.utils import write_basic_config\n",
        "\n",
        "# write_basic_config()"
      ],
      "metadata": {
        "id": "M7-MWZaLyxQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login # Give write token\n",
        "!wandb login"
      ],
      "metadata": {
        "id": "BgD0jSgo1ly8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'https://huggingface.co/datasets/GreeneryScenery/SheepsNet/resolve/main/69284.png'\n",
        "!wget 'https://huggingface.co/datasets/GreeneryScenery/SheepsNet/resolve/main/69384.png'"
      ],
      "metadata": {
        "id": "Fqv8ld6R97M0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch examples/controlnet/train_controlnet.py \\\n",
        " --pretrained_model_name_or_path=\"stabilityai/stable-diffusion-2-1-base\" \\\n",
        " --output_dir=GreeneryScenery/SheepsControlV4 \\\n",
        " --dataset_name=GreeneryScenery/SheepsNetV2 \\\n",
        " --conditioning_image_column=conditioning_image \\\n",
        " --image_column=image \\\n",
        " --caption_column=text \\\n",
        " --resolution=256 \\\n",
        " --learning_rate=1e-5 \\\n",
        " --validation_image \"69284.png\" \"69384.png\" \\\n",
        " --validation_prompt \"Sheep\" \\\n",
        " --train_batch_size=4 \\\n",
        " --num_train_epochs=3 \\\n",
        " --tracker_project_name=\"controlnet\" \\\n",
        " --enable_xformers_memory_efficient_attention \\\n",
        " --checkpointing_steps=5000 \\\n",
        " --validation_steps=5000 \\\n",
        " --report_to wandb \\\n",
        " --push_to_hub"
      ],
      "metadata": {
        "id": "NZJpHOFCdQxB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}