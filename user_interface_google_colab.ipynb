{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mm8RTylKY1LW"
      },
      "source": [
        "#Setting up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJtMfi3bUS4o"
      },
      "outputs": [],
      "source": [
        "!pip install diffusers transformers accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_eJRUoQYHNn"
      },
      "outputs": [],
      "source": [
        "!accelerate config default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVBRBEWOX8y3"
      },
      "outputs": [],
      "source": [
        "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel\n",
        "from diffusers import UniPCMultistepScheduler\n",
        "from diffusers import StableDiffusionControlNetPipeline\n",
        "from diffusers.utils import load_image\n",
        "import PIL\n",
        "import torch\n",
        "import io\n",
        "from google.colab import files\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image, ImageOps\n",
        "\n",
        "import requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ct39IrD4fZV-"
      },
      "source": [
        "# Loading Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7uIuaeEzW6FF"
      },
      "outputs": [],
      "source": [
        "#@title **Hugging Face model**\n",
        "\n",
        "model_repository = 'GreeneryScenery/SheepsControlV5' #@param {type:\"string\"}\n",
        "stable_diffusion_repository = 'stabilityai/stable-diffusion-2-1-base' #@param {type:\"string\"}\n",
        "\n",
        "controlnet = ControlNetModel.from_pretrained(model_repository, torch_dtype=torch.float16)\n",
        "pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
        "    stable_diffusion_repository, controlnet=controlnet, torch_dtype=torch.float16\n",
        ")\n",
        "\n",
        "pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "\n",
        "# this command loads the individual model components on GPU on-demand.\n",
        "pipe.enable_model_cpu_offload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynslrluO7-Yt"
      },
      "source": [
        "# Preprocess Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhGArE53Tlx0"
      },
      "outputs": [],
      "source": [
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\").to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fijOxsCTYSXL"
      },
      "outputs": [],
      "source": [
        "format_open_assistant = '<|prompter|>Please form a creative sentence describing an image from these words: [|INPUT|]. This sentence will be used for image generation in ControlNet and Stable Diffusion so be as descriptive and creative as possible, while not adding too much extra stuff.<|endoftext|><|assistant|>'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvPCOc4NYCoP"
      },
      "outputs": [],
      "source": [
        "API_URL = \"https://api-inference.huggingface.co/models/OpenAssistant/oasst-sft-1-pythia-12b\"\n",
        "\n",
        "#TODO: Replace with your own API key\n",
        "headers = {\"Authorization\": \"\"}\n",
        "\n",
        "def query_oa(payload):\n",
        "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
        "\treturn response.json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hz5G60q7clNU"
      },
      "outputs": [],
      "source": [
        "def open_assistant_generator(string):\n",
        "    text_open_assistant = format_open_assistant.replace('|INPUT|', string)\n",
        "    output = query_oa({\n",
        "        \"inputs\": text_open_assistant,\n",
        "    })\n",
        "    output = output[0]['generated_text']\n",
        "    return output.replace(text_open_assistant, '')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUsDe_ACZgcI"
      },
      "outputs": [],
      "source": [
        "# open_assistant_generator('cat with flowers')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpmEsZl0amDm"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer_magic_prompt = AutoTokenizer.from_pretrained(\"Gustavosta/MagicPrompt-Stable-Diffusion\")\n",
        "model_magic_prompt = AutoModelForCausalLM.from_pretrained(\"Gustavosta/MagicPrompt-Stable-Diffusion\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIEFq6sVZNlX"
      },
      "outputs": [],
      "source": [
        "def magic_prompt_generator(string):\n",
        "    input_magic_prompt = tokenizer_magic_prompt.encode(string, return_tensors='pt')\n",
        "    output_magic_prompt = model_magic_prompt.generate(input_magic_prompt, max_length=100, do_sample=True, top_k=50, top_p=0.95, temperature=0.5, num_return_sequences=1)\n",
        "    text_magic_prompt = tokenizer_magic_prompt.decode(output_magic_prompt[0], skip_special_tokens=True)\n",
        "    return text_magic_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ci39K5yjaRej"
      },
      "outputs": [],
      "source": [
        "# print(magic_prompt_generator('cat with flowers').replace('\\n', ''))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmDX0rYC8-u_"
      },
      "outputs": [],
      "source": [
        "def canny(image):\n",
        "  return Image.fromarray(cv2.Canny(np.asarray(image), 100, 200))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHjrRF2JklVj"
      },
      "outputs": [],
      "source": [
        "# from PIL import Image\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "# canny(Image.open('10277.png'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYwerHBl8AWl"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.github.com/s9xie/hed/master/examples/hed/deploy.prototxt\n",
        "!wget https://vcl.ucsd.edu/hed/hed_pretrained_bsds.caffemodel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gA5VxPne8TIw"
      },
      "outputs": [],
      "source": [
        "net = cv2.dnn.readNetFromCaffe(\"deploy.prototxt\", \"hed_pretrained_bsds.caffemodel\")\n",
        "pad = 14"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyjSPWtG8RHe"
      },
      "outputs": [],
      "source": [
        "def caffe_hed(image):\n",
        "  img = image\n",
        "  img = np.array(img)\n",
        "  img = img[:, :, ::-1]\n",
        "  img = cv2.copyMakeBorder(img, 50, 50, 50, 50, cv2.BORDER_CONSTANT, value = (255, 255, 255))\n",
        "  (H, W) = img.shape[:2]\n",
        "  blob = cv2.dnn.blobFromImage(img, scalefactor=1.0, size=(W, H),\n",
        "      swapRB=False, crop=False)\n",
        "  net.setInput(blob)\n",
        "  hed = net.forward()\n",
        "  hed = cv2.resize(hed[0, 0], (W, H))\n",
        "  hed = (255 * hed).astype(\"uint8\")\n",
        "  blob = cv2.resize(blob[0, 0], (W, H))\n",
        "  cropped_img = hed[H-256 - pad:H - pad, W-256 - pad:W - pad]\n",
        "  return Image.fromarray(cropped_img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3Wi_6H8ZER6"
      },
      "source": [
        "#Generate image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IqilJkb8Uq_B"
      },
      "outputs": [],
      "source": [
        "#@title **Calling model**\n",
        "\n",
        "#@markdown ## Fine adjustments\n",
        "seed = 4 #@param {type:\"slider\", min:0, max:10000, step:1}\n",
        "steps = 20 #@param {type:\"slider\", min:0, max:500, step:1}\n",
        "guidance_scale = 7.5 #@param {type:\"slider\"}\n",
        "\n",
        "#@markdown ## Prompts\n",
        "caption = True #@param {type:\"boolean\"}\n",
        "open_assistant = True #@param {type:\"boolean\"}\n",
        "magic_prompt = True #@param {type:\"boolean\"}\n",
        "#@markdown  <summary>Prompt is ignored if caption is true.</sumary>\n",
        "prompt = \"\" #@param {type:\"string\"}\n",
        "negative_prompt = \"\" #@param {type:\"string\"}\n",
        "if negative_prompt == \"\":\n",
        "  negative_prompt = None\n",
        "# , trending on artstation, artstationHD, artstationHQ, patreon, 4k, 8k\n",
        "\n",
        "generator = torch.manual_seed(seed)\n",
        "\n",
        "#@markdown ## Upload image\n",
        "upload = True #@param {type:\"boolean\"}\n",
        "loaded = True #@param {type:\"boolean\"}\n",
        "#@markdown <summary>Link and filename are ignored if uploading file</summary>\n",
        "filename = 'Cute cat.png' #@param {type:\"string\"}\n",
        "link = '' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ## Preprocess image\n",
        "edge_mode = \"PIL invert\" #@param [\"None\", \"Canny\", \"Caffe HED\", \"PIL invert\"]\n",
        "\n",
        "if loaded:\n",
        "  init_image = PIL.Image.open(filename).convert(\"RGB\")\n",
        "elif not upload:\n",
        "  !wget $link\n",
        "  init_image = PIL.Image.open(filename).convert(\"RGB\")\n",
        "else:\n",
        "  uploaded = files.upload()\n",
        "  init_image = PIL.Image.open(io.BytesIO(uploaded[next(iter(uploaded))])).convert(\"RGB\")\n",
        "\n",
        "img = init_image\n",
        "width, height = img.size\n",
        "aspect_ratio = width / height\n",
        "if width > height:\n",
        "    new_height = 512\n",
        "    new_width = int(512 * aspect_ratio)\n",
        "else:\n",
        "    new_width = 512\n",
        "    new_height = int(512 / aspect_ratio)\n",
        "img = img.resize((new_width, new_height))\n",
        "if new_width > new_height:\n",
        "    left = (new_width - 512) / 2\n",
        "    top = 0\n",
        "    right = left + 512\n",
        "    bottom = 512\n",
        "else:\n",
        "    left = 0\n",
        "    top = (new_height - 512) / 2\n",
        "    right = 512\n",
        "    bottom = top + 512\n",
        "img = img.crop((left, top, right, bottom))\n",
        "init_image = img\n",
        "\n",
        "if caption:\n",
        "  # prompt = captioner(init_image, 'A sketch')[0]['generated_text']  \n",
        "  inputs = processor(init_image, 'a sketch of', return_tensors=\"pt\").to(\"cuda\")\n",
        "  out = model.generate(**inputs)\n",
        "  prompt = processor.decode(out[0], skip_special_tokens=True)\n",
        "  prompt = prompt.replace('a sketch of ', '')\n",
        "  print(prompt)\n",
        "if open_assistant:\n",
        "  prompt = open_assistant_generator(prompt)\n",
        "  print(prompt)\n",
        "if magic_prompt:\n",
        "  prompt = magic_prompt_generator(prompt)\n",
        "  print(prompt)\n",
        "\n",
        "\n",
        "if edge_mode == 'None':\n",
        "  pass\n",
        "elif edge_mode == 'Canny':\n",
        "  init_image = canny(init_image)\n",
        "elif edge_mode == 'Caffe HED':\n",
        "  init_image = caffe_hed(init_image)\n",
        "elif edge_mode == 'PIL invert':\n",
        "  init_image = ImageOps.invert(init_image)\n",
        "\n",
        "out_image = pipe(\n",
        "    prompt,\n",
        "    image = init_image,\n",
        "    num_inference_steps = steps,\n",
        "    generator = generator,\n",
        "    negative_prompt = negative_prompt,\n",
        "    guidance_scale = guidance_scale\n",
        ").images[0]\n",
        "\n",
        "init_image.show()\n",
        "out_image.show()\n",
        "\n",
        "out_image.save(f\"{prompt[:200]}.png\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Mm8RTylKY1LW",
        "Ct39IrD4fZV-",
        "ynslrluO7-Yt",
        "b3Wi_6H8ZER6"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
