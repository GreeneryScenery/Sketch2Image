{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Mm8RTylKY1LW",
        "Ct39IrD4fZV-",
        "ynslrluO7-Yt"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Setting up"
      ],
      "metadata": {
        "id": "Mm8RTylKY1LW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers transformers accelerate"
      ],
      "metadata": {
        "id": "GJtMfi3bUS4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate config default"
      ],
      "metadata": {
        "id": "O_eJRUoQYHNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel\n",
        "from diffusers import UniPCMultistepScheduler\n",
        "from diffusers import StableDiffusionControlNetPipeline\n",
        "from diffusers.utils import load_image\n",
        "import PIL\n",
        "import torch\n",
        "import io\n",
        "from google.colab import files\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "IVBRBEWOX8y3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Model"
      ],
      "metadata": {
        "id": "Ct39IrD4fZV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Hugging Face model**\n",
        "\n",
        "model_repository = 'GreeneryScenery/SheepsControlV4' #@param {type:\"string\"}\n",
        "stable_diffusion_repository = 'stabilityai/stable-diffusion-2-1-base' #@param {type:\"string\"}\n",
        "\n",
        "controlnet = ControlNetModel.from_pretrained(model_repository, torch_dtype=torch.float16)\n",
        "pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
        "    stable_diffusion_repository, controlnet=controlnet, torch_dtype=torch.float16\n",
        ")\n",
        "\n",
        "pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "\n",
        "# this command loads the individual model components on GPU on-demand.\n",
        "pipe.enable_model_cpu_offload()"
      ],
      "metadata": {
        "id": "7uIuaeEzW6FF",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess Image"
      ],
      "metadata": {
        "id": "ynslrluO7-Yt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def canny(image):\n",
        "  return Image.fromarray(cv2.Canny(np.asarray(image), 100, 200))"
      ],
      "metadata": {
        "id": "dmDX0rYC8-u_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from PIL import Image\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "# canny(Image.open('10277.png'))"
      ],
      "metadata": {
        "id": "CHjrRF2JklVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.github.com/s9xie/hed/master/examples/hed/deploy.prototxt\n",
        "!wget https://vcl.ucsd.edu/hed/hed_pretrained_bsds.caffemodel"
      ],
      "metadata": {
        "id": "wYwerHBl8AWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = cv2.dnn.readNetFromCaffe(\"deploy.prototxt\", \"hed_pretrained_bsds.caffemodel\")\n",
        "pad = 14"
      ],
      "metadata": {
        "id": "gA5VxPne8TIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def caffe_hed(image):\n",
        "  img = image\n",
        "  img = np.array(img)\n",
        "  img = img[:, :, ::-1]\n",
        "  img = cv2.copyMakeBorder(img, 50, 50, 50, 50, cv2.BORDER_CONSTANT, value = (255, 255, 255))\n",
        "  (H, W) = img.shape[:2]\n",
        "  blob = cv2.dnn.blobFromImage(img, scalefactor=1.0, size=(W, H),\n",
        "      swapRB=False, crop=False)\n",
        "  net.setInput(blob)\n",
        "  hed = net.forward()\n",
        "  hed = cv2.resize(hed[0, 0], (W, H))\n",
        "  hed = (255 * hed).astype(\"uint8\")\n",
        "  blob = cv2.resize(blob[0, 0], (W, H))\n",
        "  cropped_img = hed[H-256 - pad:H - pad, W-256 - pad:W - pad]\n",
        "  return Image.fromarray(cropped_img)"
      ],
      "metadata": {
        "id": "XyjSPWtG8RHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generate image"
      ],
      "metadata": {
        "id": "b3Wi_6H8ZER6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Calling model**\n",
        "\n",
        "seed = 1 #@param {type:\"slider\", min:0, max:10000, step:1}\n",
        "prompt = \"Cute turtle\" #@param {type:\"string\"}\n",
        "# , trending on artstation, artstationHD, artstationHQ, patreon, 4k, 8k\n",
        "\n",
        "generator = torch.manual_seed(seed)\n",
        "\n",
        "filename = 'TurtlehappyhighlydetailedartgermartstationconceptartmattesharpfocusartbyWLOPandJamesJeanandVictoNgai_input.png' #@param {type:\"string\"}\n",
        "\n",
        "preprocess = True #@param {type:\"boolean\"}\n",
        "mode = \"canny\" #@param [\"canny\", \"caffe_hed\"]\n",
        "upload = True #@param {type:\"boolean\"}\n",
        "loaded = False #@param {type:\"boolean\"}\n",
        "\n",
        "if loaded:\n",
        "  init_image = PIL.Image.open(filename).convert(\"RGB\")\n",
        "elif not upload:\n",
        "  #@markdown  Link and filename are ignored if uploading file\n",
        "  repository = 'GreeneryScenery/SheepsControlV3' #@param {type:\"string\"}\n",
        "  link = f'https://huggingface.co/{repository}/resolve/main/{filename}' #@param {type:\"string\"}\n",
        "  !wget $link\n",
        "  init_image = PIL.Image.open(filename).convert(\"RGB\")\n",
        "else:\n",
        "  uploaded = files.upload()\n",
        "  init_image = PIL.Image.open(io.BytesIO(uploaded[next(iter(uploaded))])).convert(\"RGB\")\n",
        "\n",
        "init_image.thumbnail((256, 256))\n",
        "\n",
        "if preprocess:\n",
        "  if mode == 'canny':\n",
        "    init_image = canny(init_image)\n",
        "  elif mode == 'caffe_hed':\n",
        "    init_image = caffe_hed(init_image)\n",
        "\n",
        "out_image = pipe(\n",
        "    prompt, num_inference_steps=20, generator=generator, image=init_image\n",
        ").images[0]\n",
        "\n",
        "init_image.show()\n",
        "out_image.show()\n",
        "\n",
        "out_image.save(f\"{prompt}.png\")"
      ],
      "metadata": {
        "id": "IqilJkb8Uq_B",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}