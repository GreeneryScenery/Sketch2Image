{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C52cF49itThe"
      },
      "source": [
        "# Setting up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TErk3qLqtWdq"
      },
      "outputs": [],
      "source": [
        "# For Google Colab\n",
        "# !pip install quickdraw ipyplot plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATVXzwrDtThk",
        "outputId": "499120bb-f3c5-47cd-a8d7-daf24967ad4a"
      },
      "outputs": [],
      "source": [
        "from quickdraw_preprocess_gan import *\n",
        "import tensorflow as tf\n",
        "\n",
        "number_of_names = 10\n",
        "number_of_drawings = max_drawings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qe73I78p3ar9"
      },
      "outputs": [],
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus: \n",
        "    tf.config.experimental.set_memory_growth(gpu, True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3g_B3kEUtThm"
      },
      "source": [
        "# Creating and preprocessing dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "YigxRB_g2_xz",
        "outputId": "2ae9ce70-f344-48c2-e0bc-7c2bc25d4977"
      },
      "outputs": [],
      "source": [
        "random_image = random_image(1)\n",
        "random_image_array = preprocess_image(random_image)\n",
        "unprocess_array(random_image_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y45Sm9YqtThn",
        "outputId": "4cdbb0c1-1739-409e-e56a-185150cd9935"
      },
      "outputs": [],
      "source": [
        "random_names = random_names(number_of_names, seed = 3) # 2\n",
        "random_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBtKn0OmtThp",
        "outputId": "a63e7bea-826d-4e28-b64b-fe9826974805"
      },
      "outputs": [],
      "source": [
        "random_names_image_dict = image_dict_names(random_names)\n",
        "random_names_image_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RO7xc-4KtThp"
      },
      "outputs": [],
      "source": [
        "# plot_image_dict_tabs(random_names_image_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpYMCgrkegf5"
      },
      "outputs": [],
      "source": [
        "examples, labels = preprocess_image_dict_to_arrays(random_names_image_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOyeBrf8tThr"
      },
      "outputs": [],
      "source": [
        "# ipyplot.plot_class_tabs(images = examples, labels = labels, max_imgs_per_tab = 6, img_width = 128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BOFhFV_tThs",
        "outputId": "a9503b91-0788-49c3-f3b5-9556055e8fcd"
      },
      "outputs": [],
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(examples)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9524R12tTht",
        "outputId": "8a262133-4600-4f8d-80b5-962375ad54fb"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(buffer_size = number_of_names * number_of_drawings)\n",
        "dataset = dataset.repeat(500)\n",
        "dataset = dataset.batch(128)\n",
        "dataset = dataset.prefetch(64)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjnJ0EbntThu",
        "outputId": "9affd2fa-d1aa-48b3-d5b5-9cb1a184d52a"
      },
      "outputs": [],
      "source": [
        "dataset_iterator = dataset.as_numpy_iterator()\n",
        "dataset_iterator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtYhjlR-tThw",
        "outputId": "b83f9b6c-480f-467b-e78b-4f5f88a7f7da"
      },
      "outputs": [],
      "source": [
        "batch = dataset_iterator.next()\n",
        "batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRmGH0M5tThx"
      },
      "outputs": [],
      "source": [
        "# ipyplot.plot_images(images = batch, max_images = 6, img_width = 128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drb_3Tdq7G2n"
      },
      "source": [
        "# Building GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0V3rk2Q688tm"
      },
      "outputs": [],
      "source": [
        "# Bring in the sequential api for the generator and discriminator\n",
        "from tensorflow.keras.models import Sequential\n",
        "# Bring in the layers for the neural network\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Reshape, LeakyReLU, Dropout, UpSampling2D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsgiKByIATOx"
      },
      "source": [
        "## Building generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpNYe4FfAVxp"
      },
      "outputs": [],
      "source": [
        "def build_generator(): \n",
        "    model = Sequential()\n",
        "\n",
        "    # Takes in random values and reshapes it to 7x7x128\n",
        "    # Beginnings of a generated image\n",
        "    model.add(Dense(7*7*128, input_dim=128))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(Reshape((7,7,128)))\n",
        "\n",
        "    # Upsampling block 1 \n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(128, 5, padding='same'))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "\n",
        "    # Upsampling block 2 \n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(128, 5, padding='same'))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "\n",
        "    # Convolutional block 1\n",
        "    model.add(Conv2D(128, 4, padding='same'))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "\n",
        "    # Convolutional block 2\n",
        "    model.add(Conv2D(128, 4, padding='same'))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "\n",
        "    # Conv layer to get to one channel\n",
        "    model.add(Conv2D(1, 4, padding='same', activation='sigmoid'))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2alDjkfjAYr9"
      },
      "outputs": [],
      "source": [
        "generator = build_generator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCWyAuBFAZ-r",
        "outputId": "06ebaaca-4d83-4011-eb5e-11adc2d5ac68"
      },
      "outputs": [],
      "source": [
        "generator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uil68RCrAbf4",
        "outputId": "c6af5766-c509-4918-ce05-7e8bade255e5"
      },
      "outputs": [],
      "source": [
        "img = generator.predict(np.random.randn(4,128,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "id": "rdnBajzYBxb6",
        "outputId": "40e614ec-6c67-46d0-d883-00ba1d4bbd41"
      },
      "outputs": [],
      "source": [
        "unprocess_array(img[0, :, :, 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6h8K7FuiEYOZ"
      },
      "source": [
        "## Building discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_3p6SRAB6TP"
      },
      "outputs": [],
      "source": [
        "def build_discriminator(): \n",
        "    model = Sequential()\n",
        "    \n",
        "    # First Conv Block\n",
        "    model.add(Conv2D(32, 5, input_shape = (28,28,1)))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(Dropout(0.4))\n",
        "    \n",
        "    # Second Conv Block\n",
        "    model.add(Conv2D(64, 5))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(Dropout(0.4))\n",
        "    \n",
        "    # Third Conv Block\n",
        "    model.add(Conv2D(128, 5))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(Dropout(0.4))\n",
        "    \n",
        "    # Fourth Conv Block\n",
        "    model.add(Conv2D(256, 5))\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(Dropout(0.4))\n",
        "    \n",
        "    # Flatten then pass to dense layer\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    \n",
        "    return model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MexQZeGvEfXI"
      },
      "outputs": [],
      "source": [
        "discriminator = build_discriminator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwkyhlFlEgac",
        "outputId": "76333577-715a-46b6-ee81-4642d6f24f45"
      },
      "outputs": [],
      "source": [
        "discriminator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MF1ilT8Eh0Q",
        "outputId": "e81c05a9-bdbd-4965-a7a5-47a1a8fac992"
      },
      "outputs": [],
      "source": [
        "discriminator.predict(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrgGsTVUEps5"
      },
      "source": [
        "# Training GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_lI-JGZdZCa"
      },
      "source": [
        "## Preparing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkPKcXm9Er2F"
      },
      "outputs": [],
      "source": [
        "# Adam is going to be the optimizer for both\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# Binary cross entropy is going to be the loss for both \n",
        "from tensorflow.keras.losses import BinaryCrossentropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0l15ajkqEtvw"
      },
      "outputs": [],
      "source": [
        "g_opt = Adam(learning_rate=0.0001) \n",
        "d_opt = Adam(learning_rate=0.00001) \n",
        "g_loss = BinaryCrossentropy()\n",
        "d_loss = BinaryCrossentropy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5OeE0l7Evcm"
      },
      "outputs": [],
      "source": [
        "# Importing the base model class to subclass our training step \n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vqrTamBEwlN"
      },
      "outputs": [],
      "source": [
        "class GAN(Model): \n",
        "    def __init__(self, generator, discriminator, *args, **kwargs):\n",
        "        # Pass through args and kwargs to base class \n",
        "        super().__init__(*args, **kwargs)\n",
        "        \n",
        "        # Create attributes for gen and disc\n",
        "        self.generator = generator \n",
        "        self.discriminator = discriminator \n",
        "        \n",
        "    def compile(self, g_opt, d_opt, g_loss, d_loss, *args, **kwargs): \n",
        "        # Compile with base class\n",
        "        super().compile(*args, **kwargs)\n",
        "        \n",
        "        # Create attributes for losses and optimizers\n",
        "        self.g_opt = g_opt\n",
        "        self.d_opt = d_opt\n",
        "        self.g_loss = g_loss\n",
        "        self.d_loss = d_loss \n",
        "\n",
        "    def train_step(self, batch):\n",
        "        # Get the data \n",
        "        real_images = batch\n",
        "        fake_images = self.generator(tf.random.normal((128, 128, 1)), training=False)\n",
        "        \n",
        "        # Train the discriminator\n",
        "        with tf.GradientTape() as d_tape: \n",
        "            # Pass the real and fake images to the discriminator model\n",
        "            yhat_real = self.discriminator(real_images, training=True) \n",
        "            yhat_fake = self.discriminator(fake_images, training=True)\n",
        "            yhat_realfake = tf.concat([yhat_real, yhat_fake], axis=0)\n",
        "            \n",
        "            # Create labels for real and fakes images\n",
        "            y_realfake = tf.concat([tf.zeros_like(yhat_real), tf.ones_like(yhat_fake)], axis=0)\n",
        "            \n",
        "            # Add some noise to the TRUE outputs\n",
        "            noise_real = 0.15*tf.random.uniform(tf.shape(yhat_real))\n",
        "            noise_fake = -0.15*tf.random.uniform(tf.shape(yhat_fake))\n",
        "            y_realfake += tf.concat([noise_real, noise_fake], axis=0)\n",
        "            \n",
        "            # Calculate loss - BINARYCROSS \n",
        "            total_d_loss = self.d_loss(y_realfake, yhat_realfake)\n",
        "            \n",
        "        # Apply backpropagation - nn learn \n",
        "        dgrad = d_tape.gradient(total_d_loss, self.discriminator.trainable_variables) \n",
        "        self.d_opt.apply_gradients(zip(dgrad, self.discriminator.trainable_variables))\n",
        "        \n",
        "        # Train the generator \n",
        "        with tf.GradientTape() as g_tape: \n",
        "            # Generate some new images\n",
        "            gen_images = self.generator(tf.random.normal((128,128,1)), training=True)\n",
        "                                        \n",
        "            # Create the predicted labels\n",
        "            predicted_labels = self.discriminator(gen_images, training=False)\n",
        "                                        \n",
        "            # Calculate loss - trick to training to fake out the discriminator\n",
        "            total_g_loss = self.g_loss(tf.zeros_like(predicted_labels), predicted_labels) \n",
        "            \n",
        "        # Apply backprop\n",
        "        ggrad = g_tape.gradient(total_g_loss, self.generator.trainable_variables)\n",
        "        self.g_opt.apply_gradients(zip(ggrad, self.generator.trainable_variables))\n",
        "        \n",
        "        return {\"d_loss\":total_d_loss, \"g_loss\":total_g_loss}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiAiub1tE4wP"
      },
      "outputs": [],
      "source": [
        "# Create instance of subclassed model\n",
        "gan = GAN(generator, discriminator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqGXpFlIE664"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "gan.compile(g_opt, d_opt, g_loss, d_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HzZJLhrUE74Y"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from tensorflow.keras.preprocessing.image import array_to_img\n",
        "from tensorflow.keras.callbacks import Callback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PGmh7QIE-i1"
      },
      "outputs": [],
      "source": [
        "class ModelMonitor(Callback):\n",
        "    def __init__(self, num_img=3, latent_dim=128):\n",
        "        self.num_img = num_img\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        random_latent_vectors = tf.random.uniform((self.num_img, self.latent_dim,1))\n",
        "        generated_images = self.model.generator(random_latent_vectors)\n",
        "        generated_images *= 255\n",
        "        generated_images.numpy()\n",
        "        for i in range(self.num_img):\n",
        "            img = array_to_img(generated_images[i])\n",
        "            img.save(os.path.join('images', f'generated_img_{epoch}_{i}.png'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iiizxzIOYNf"
      },
      "outputs": [],
      "source": [
        "image_dir = 'images'\n",
        "\n",
        "if not os.path.exists(image_dir):\n",
        "    os.mkdir(image_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rr7Duzg8dcoq"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "J1voe9l3FAei",
        "outputId": "8f740015-1ac3-4a01-ef3a-6eb2a864828b"
      },
      "outputs": [],
      "source": [
        "# Recommend 2000 epochs\n",
        "history = gan.fit(dataset, epochs = 500, callbacks=[ModelMonitor()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lA_53oFYs-q"
      },
      "source": [
        "# Saving models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEHHL4LLFF4J"
      },
      "outputs": [],
      "source": [
        "generator.save('generator_2.h5')\n",
        "discriminator.save('discriminator_2.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ww_Smlv2P8jU"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('generator_2.h5')\n",
        "files.download('discriminator_2.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RdiIWcoamDg"
      },
      "outputs": [],
      "source": [
        "generator = build_generator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZAZYmMnGQZV"
      },
      "outputs": [],
      "source": [
        "generator.load_weights('generator_2.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOdfAUbatjcP"
      },
      "outputs": [],
      "source": [
        "!zip -r images.zip images/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTCE9YcqyiVz"
      },
      "outputs": [],
      "source": [
        "files.download('images.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2J2wEwvFE_8"
      },
      "source": [
        "# Plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ig6t0aofGRlM"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Create figure with secondary y-axis\n",
        "fig = make_subplots()\n",
        "\n",
        "# Add traces\n",
        "fig.add_trace(\n",
        "    go.Scatter(y = history.history['d_loss'], name = 'd_loss'),\n",
        "    secondary_y = False\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(y = history.history['g_loss'], name = 'g_loss'),\n",
        "    secondary_y = False\n",
        ")\n",
        "\n",
        "# Add figure title\n",
        "fig.update_layout(\n",
        "    title_text = 'Loss of GAN Model'\n",
        ")\n",
        "\n",
        "# Set x-axis title\n",
        "fig.update_xaxes(title_text = 'Epoch')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuUqfbQqaM8K"
      },
      "source": [
        "# Testing model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGot70QAGJgd"
      },
      "outputs": [],
      "source": [
        "imgs = generator.predict(tf.random.normal((1, 128, 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnDZz6ZhZWbC"
      },
      "outputs": [],
      "source": [
        "array_to_img(imgs[0])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "x_lI-JGZdZCa"
      ],
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "search_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
